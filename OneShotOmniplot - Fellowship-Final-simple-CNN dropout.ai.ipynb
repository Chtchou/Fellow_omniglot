{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot learning - Omniglot - Fellowship.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fellowship.ai - Few-shot learning\n",
    "This is my personal project to the few-shot learning challenge from [Fellowship.ai](https://fellowship.ai/challenge/) with the following goal:\n",
    "> Omniglot, the “transpose” of MNIST, with 1623 character classes, each with 20 examples.  Build a few-shot classifier with a target of <35% error.\n",
    "\n",
    "#### Omniglot - Dataset\n",
    "*Dataset reference:* [Link](https://github.com/brendenlake/omniglot)\n",
    "> Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332-1338.\n",
    "\n",
    "The Omniglot dataset is often considered as the transpose of the MNIST dataset. While the latter contains only 10 classes with a training set of 60000 examples, Omniglot contains an important number of classes (1623 different handwritten characters from 50 different alphabets) with only a low number of examples (20) for each, making it an ideal dataset for few-shot learning problems.\n",
    "\n",
    "#### Few-shot learning\n",
    "Whereas, lots of deep learning projects are based on a huge number of training examples to be trained, few-shot learning is  based only on a few one. This approach is much closer to the one experienced by humans. We are able to memorize and recognize objects we have never seen before from a few number of examples. Then for each new encounter with these types of object we can classify them in an accurate and easy way.\n",
    "\n",
    "\n",
    "#### Stategy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, concatenate,AveragePooling2D, MaxPooling2D, Dropout, Lambda, Add\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image                                                                                                                               \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.transform import resize\n",
    "import h5py\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indicate the PATH of the training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training images path\n",
    "PATH=\"images_background/\"\n",
    "\n",
    "#Validation and test images path\n",
    "PATH_TEST = \"images_evaluation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a look at the list of all alphabets contained in the training set, and their total number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of the different alphabets:\n",
      " ['Alphabet_of_the_Magi' 'Anglo-Saxon_Futhorc' 'Arcadian' 'Armenian'\n",
      " 'Asomtavruli_(Georgian)' 'Balinese' 'Bengali'\n",
      " 'Blackfoot_(Canadian_Aboriginal_Syllabics)' 'Braille' 'Burmese_(Myanmar)'\n",
      " 'Cyrillic' 'Early_Aramaic' 'Futurama' 'Grantha' 'Greek' 'Gujarati'\n",
      " 'Hebrew' 'Inuktitut_(Canadian_Aboriginal_Syllabics)'\n",
      " 'Japanese_(hiragana)' 'Japanese_(katakana)' 'Korean' 'Latin'\n",
      " 'Malay_(Jawi_-_Arabic)' 'Mkhedruli_(Georgian)' 'N_Ko'\n",
      " 'Ojibwe_(Canadian_Aboriginal_Syllabics)' 'Sanskrit' 'Syriac_(Estrangelo)'\n",
      " 'Tagalog' 'Tifinagh']\n",
      "\n",
      "Number of different alphabets: 30\n"
     ]
    }
   ],
   "source": [
    "alph_type = np.array(os.listdir(PATH)) #Give the different types of alphabet in our training data\n",
    "print(f\"List of the different alphabets:\\n {alph_type}\")\n",
    "print(f\"\\nNumber of different alphabets: {len(alph_type)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check the number of character for each alphabets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAE8CAYAAADQaEpSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXfcJEXx/9+fC3AESXIgchyHcIiKJI98ioL4U4IoURQERNCvCRQDYkKCKAYkKUHCiUgGJSkgHFkO78hRchAEJJ4gKFC/P6rnntnZ2d3ZfdI9Q71fr3ntzkxNd0+q6a6urpaZEQRBEIx8Rg13AYIgCIKBIRR6EARBTQiFHgRBUBNCoQdBENSEUOhBEAQ1IRR6EARBTQiFXkMknSjpgGHKW5JOkPSspOu7PPZBSR8crLIFzUgySSsMtGzJsXFvh4BQ6ENAepifkLRAbttnJV0+jMUaLKYCGwMTzGyt4S5ML0i6XNJnh7scgRMfg+qEQh86xgB7DHchukXS6C4PWRZ40MxeHIzyVCG1Eobt2e7hmg1UvmOGI99g7iEU+tDxU+DrkhYp7pA0KTVnx+S2zaklStpZ0jWSDpH0nKT7Ja2Xtj8i6UlJOxWSXVzSJZJmS7pC0rK5tFdK+56RdLekbXP7TpT0a0kXSnoR+EBJed8q6dx0/L2SdkvbdwV+A6wr6d+Sflh2ISTtJunOVLY7JK2R272apFskPS/pNEnj0jGLSjpf0lPJnHO+pAmF63WgpGuAl4C3Sdoll8/9kj5XKMcWkm6S9IKk+yR9WNKBwHuBI9I5HNHLNZO0STq32ZL+IenrLa5Fdm8PT+d8l6SNcvsXlnScpMdTOgdkH4zCc/EMsG9J+mtJ+mt6bh6XdISkeVqU5URJR7V6bhIflHRPugdHSlI6dnlJl0l6WtK/JJ1c8qyvma7Js3Kz3Lhc3pule/GcpGslrZK2nwRMBM5L9+ObZWUPEmYWyyAvwIPAB4GzgQPSts8Cl6f/kwADxuSOuRz4bPq/M/AqsAswGjgAeBg4EpgX+BAwG1gwyZ+Y1t+X9h8KXJ32LQA8ktIaA6wB/At4V+7Y54H18Q/+uJLzuQL4FTAOWA14CtgoV9ar21yLbYB/AGsCAlYAls1dp+uBtwKLAXcCn0/73gxsBcwPvAk4A/hD4Xo9DLwrnddYYFNg+ZTPBriiXyPJr5XOc+N0nksDKxWvfa/XDHgceG/av2iWb8n1yO7tV1OZt0tpLZb2/wE4OpVhiXR9Plc49supXPOVpP8eYJ20f1K6pnvm9huwQqfnJid7PrAIrmSfAj6c9q2QruW8wHjgSuCXhXfgNmCZdG+voe9dWAN4Elgbf753SvLz5t+f4X6PR8Iy7AV4Iyz0KfSV08s6nu4V+j25fe9O8kvmtj0NrJb+nwicmtu3IPBaepm2A64qlO9o4Ae5Y3/b5lyWSWm9KbftIODEXFnbKfSLgD3aXKcdcusHA0e1kF0NeLZwvfbrcB/+kOWdzvmQFnJzrn1a7/qa4R+XzwELdSjTzsBjgHLbrgd2BJYEXiGnqIHtgem5Yx/u8lncEzgnt15U6KXPTU52am7/6cDeLfL5GHBj4d5+Pre+CXBf+v9rYP/C8XcDG+Tfn17evTfaEiaXIcTMbsNrOHv3cPgTuf//SekVty2YW38kl++/gWfwmu+ywNqpafucpOeATwFvKTu2hLcCz5jZ7Ny2h/AabhWWAe5rs/+fuf8vkc5J0vySjpb0kKQX8BrgImq0VzeUW9JHJF2XzCTP4Upk8YrlyNPLNdsq5fdQMl2s2yb9f1jSXImH6LtXY4HHc/kejdfUW+XbgKQVk3nqn+m6/Yi+a1BGq+cmo9X9WULSqcks9ALwu5J88mXNzpF0nnsVru8yhXyDCoRCH3p+AOxGowLMOhDnz23LK4teWCb7I2lBvJn7GP5SXWFmi+SWBc3s/3LHtgvB+RiwmKQ35bZNxM0oVXgEN4N0y17A24G1zWwh3CwAbk7JmFNuSfMCZwE/w1syiwAX5uTblaN4/l1fMzP7m5ltgSvfP+C12VYsndmiExPpu1evAIvn8l3IzN7VpqxFfg3cBUxO120fGq9ZkVbPTScOSmVZJeWzQ0k+y+T+Z+cIfp4HFq7v/GZ2StofIWErEgp9iDGze4HTgK/ktj2FK8QdJI2W9Bl6U3p5NpE0NXWA7Q/MMLNH8BbCipJ2lDQ2LWtKekfF8j8CXAscJGlc6rzaFTi5Yrl+g3cOv0fOCiUdb2W8CW+FPCdpMfzD2I55cHvuU8Crkj6C9zVkHAfsImkjSaMkLS1ppbTvCeBtOdmurpmkeSR9StLCZvY/4AXcdNGKJYCvpHS3Ad4BXGhmjwMXAz+XtFAq5/KSNuhw7nnelPL/dzq//+sg3+q5qZLPv/H7szTwjRKZL0qakO7fPvh7AHAs8HlJa6dnYgFJm+YqDcX7EbQgFPrwsB/eyZVnN/wleBrv2Lu2n3n8Hld6z+AdY58CSKaSDwGfwGtI/wR+giu/qmyP2/0fA87BbcmXVDnQzM4ADkzlm43XXhercOgvgfnwzsjrgD93yGc2/tE8HXgW+CRwbm7/9Xgn5yF4v8YVeNMfvDNw6+SNcViP12xH4MFkfvg8XmNtxQxgcjq3A4GtzezptO/T+MfpjnQeZwJLtTv3Al/Hz302rjhPay9e/txU4Id45+bzwAW4A0BZ2hcD96flAAAzm4k//0fg53gv3j+QcRDw3WSOKfUWChw1mu6CIBhKJO2Md8BOnQvKciLwqJl9d7jLEvRG1NCDIAhqQij0IAiCmhAmlyAIgpoQNfQgCIKaMKTBfBZffHGbNGnSUGYZBEEw4pk1a9a/zGx8J7khVeiTJk1i5syZQ5llEATBiEfSQ1XkwuQSBEFQE0KhB0EQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE0KhB0EQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE4Z0pGgQBEEdmbT3BW33P/jjTYekHFFDD4IgqAmh0IMgCGpCKPQgCIKaEAo9CIKgJoRCD4IgqAmh0IMgCGpCKPQgCIKaEAo9CIKgJoRCD4IgqAmh0IMgCGpCDP0PgrmAuWXoeDCyiRp6EARBTQiFHgRBUBNCoQdBENSESjZ0SQ8Cs4HXgFfNbIqkxYDTgEnAg8C2Zvbs4BQzCIIg6EQ3NfQPmNlqZjYlre8NXGpmk4FL03oQBEEwTPTH5LIFMC39nwZ8rP/FCYIgCHqlqkI34GJJsyTtnrYtaWaPA6TfJQajgEEQBEE1qvqhr29mj0laArhE0l1VM0gfgN0BJk6c2EMRgyAIgipUqqGb2WPp90ngHGAt4AlJSwGk3ydbHHuMmU0xsynjx48fmFIHQRAETXRU6JIWkPSm7D/wIeA24FxgpyS2E/DHwSpkEARB0JkqJpclgXMkZfK/N7M/S/obcLqkXYGHgW0Gr5hBEARBJzoqdDO7H1i1ZPvTwEaDUaggCIKge2KkaBAEQU0IhR4EQVATInxuECQihG0w0okaehAEQU0IhR4EQVATQqEHQRDUhLChB8EIIuz8QTuihh4EQVATQqEHQRDUhFDoQRAENSFs6HMxYS8NgqAbooYeBEFQE0KhB0EQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE0KhB0EQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE0KhB0EQ1IQY+h+MWCI0QhA0EjX0IAiCmhAKPQiCoCaEQg+CIKgJYUMPgqA2vNH7VaKGHgRBUBNCoQdBENSEMLlU4I3ejAuCboj3ZfioXEOXNFrSjZLOT+vLSZoh6R5Jp0maZ/CKGQRBEHSiG5PLHsCdufWfAIeY2WTgWWDXgSxYEARB0B2VFLqkCcCmwG/SuoANgTOTyDTgY4NRwCAIgqAaVW3ovwS+Cbwprb8ZeM7MXk3rjwJLlx0oaXdgd4CJEyf2XtIRQNgOg7mFwXgW4/me++lYQ5e0GfCkmc3Kby4RtbLjzewYM5tiZlPGjx/fYzGDIAiCTlSpoa8PfFTSJsA4YCG8xr6IpDGplj4BeGzwihkEQRB0omMN3cy+bWYTzGwS8AngMjP7FDAd2DqJ7QT8cdBKGQRBEHSkPwOLvgV8TdK9uE39uIEpUhAEQdALXQ0sMrPLgcvT//uBtQa+SEEQBEEvxND/IAiCmhAKPQiCoCaEQg+CIKgJodCDIAhqQij0IAiCmhAKPQiCoCaEQg+CIKgJodCDIAhqQij0IAiCmhAKPQiCoCaEQg+CIKgJodCDIAhqQij0IAiCmhAKPQiCoCaEQg+CIKgJodCDIAhqQij0IAiCmtDVjEXBG4dJe1/Qdv+DP950iEoSBEFVooYeBEFQE0KhB0EQ1IRQ6EEQBDUhbOhBvwhbe9Ar8ewMPFFDD4IgqAmh0IMgCGpCKPQgCIKaEAo9CIKgJoRCD4IgqAmh0IMgCGpCKPQgCIKa0FGhSxon6XpJN0u6XdIP0/blJM2QdI+k0yTNM/jFDYIgCFpRpYb+CrChma0KrAZ8WNI6wE+AQ8xsMvAssOvgFTMIgiDoREeFbs6/0+rYtBiwIXBm2j4N+NiglDAIgiCoRCUbuqTRkm4CngQuAe4DnjOzV5PIo8DSLY7dXdJMSTOfeuqpgShzEARBUEIlhW5mr5nZasAEYC3gHWViLY49xsymmNmU8ePH917SIAiCoC1debmY2XPA5cA6wCKSsuBeE4DHBrZoQRAEQTdU8XIZL2mR9H8+4IPAncB0YOskthPwx8EqZBAEQdCZKuFzlwKmSRqNfwBON7PzJd0BnCrpAOBG4LhBLGdlIiRnEARvVDoqdDO7BVi9ZPv9uD09CIIgmAuIkaJBEAQ1IRR6EARBTQiFHgRBUBNCoQdBENSEUOhBEAQ1IRR6EARBTQiFHgRBUBNCoQdBENSEUOhBEAQ1ocrQ/1rSKUQA1DNMwEgIjTASylgn4nrXh6ihB0EQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE0KhB0EQ1IRQ6EEQBDXhDeu2OJyEm9jQEtc7eKMQNfQgCIKaEAo9CIKgJoRCD4IgqAlhQw+C4A1HXftVooYeBEFQE0KhB0EQ1IRQ6EEQBDUhbOjBkFCncMV1OpegXkQNPQiCoCaEQg+CIKgJodCDIAhqQkeFLmkZSdMl3Snpdkl7pO2LSbpE0j3pd9HBL24QBEHQiio19FeBvczsHcA6wBclvRPYG7jUzCYDl6b1IAiCYJjoqNDN7HEzuyH9nw3cCSwNbAFMS2LTgI8NViGDIAiCznTltihpErA6MANY0sweB1f6kpZocczuwO4AEydO7LmgdR2qGwRBMFBU7hSVtCBwFrCnmb1Q9TgzO8bMppjZlPHjx/dSxiAIgqAClRS6pLG4Mj/ZzM5Om5+QtFTavxTw5OAUMQiCIKhCFS8XAccBd5rZL3K7zgV2Sv93Av448MULgiAIqlLFhr4+sCNwq6Sb0rZ9gB8Dp0vaFXgY2GZwihgEQRBUoaNCN7OrAbXYvdHAFicIgiDolRgpGgRBUBNCoQdBENSEUOhBEAQ1IRR6EARBTQiFHgRBUBNCoQdBENSEmIIuCIKgBSMthlTU0IMgCGpCKPQgCIKaEAo9CIKgJoQNPQgGkZFmgw1GNlFDD4IgqAmh0IMgCGpCKPQgCIKaEAo9CIKgJoRCD4IgqAmh0IMgCGpCuC3WhHCPC+pKp2cb4vnOiBp6EARBTQiFHgRBUBNCoQdBENSEUOhBEAQ1IRR6EARBTQiFHgRBUBNCoQdBENSEUOhBEAQ1IRR6EARBTQiFHgRBUBNCoQdBENSEjgpd0vGSnpR0W27bYpIukXRP+l10cIsZBEEQdKJKDf1E4MOFbXsDl5rZZODStB4EQRAMIx0VupldCTxT2LwFMC39nwZ8bIDLFQRBEHRJrzb0Jc3scYD0u0QrQUm7S5opaeZTTz3VY3ZBEARBJwa9U9TMjjGzKWY2Zfz48YOdXRAEwRuWXhX6E5KWAki/Tw5ckYIgCIJe6FWhnwvslP7vBPxxYIoTBEEQ9EoVt8VTgL8Cb5f0qKRdgR8DG0u6B9g4rQdBEATDSMc5Rc1s+xa7NhrgsgRBEAT9IEaKBkEQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE0KhB0EQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE0KhB0EQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE0KhB0EQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE0KhB0EQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE0KhB0EQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE0KhB0EQ1IRQ6EEQBDUhFHoQBEFNCIUeBEFQE0KhB0EQ1IR+KXRJH5Z0t6R7Je09UIUKgiAIuqdnhS5pNHAk8BHgncD2kt45UAULgiAIuqM/NfS1gHvN7H4z+y9wKrDFwBQrCIIg6BaZWW8HSlsDHzazz6b1HYG1zexLBbndgd3T6tuBu3svbgOLA/8aQLnBSHO45IYz7zfiuQxn3nEuc2fe3ZSxCsua2fiOUmbW0wJsA/wmt74jcHiv6fWQ/8yBlBuMNIdLbiSUsU7nMhLKGOcyd8oN9NIfk8ujwDK59QnAY/1ILwiCIOgH/VHofwMmS1pO0jzAJ4BzB6ZYQRAEQbeM6fVAM3tV0peAi4DRwPFmdvuAlawzxwyw3GCkOVxyw5n3G/FchjPvOJe5M+9uyjhg9NwpGgRBEMxdxEjRIAiCmhAKPQiCoCaEQg+CIKgJI06hS5pH0sppGTvc5ekvkhYYwrwOH6q8gmpImiRp4zb7JWmCpEkd0pGkCQNdvpJ83jZA6Xx7INIpSXebKtu6SO9ZSc8UlgcknZG/J5JWlHSspIslXZYtvebbc3lHUqeopPcD04AHAeF+8DuZ2ZU5mYWBfYH3pk1XAPuZ2fMl6c0LbAVMIufxY2b7FeTGA7uVyH0m7V+sXbnN7JmSvNcDfgMsaGYTJa0KfM7MvpD2/9LM9pR0HtB0k8zso+3yLEPSDWa2Rvq/LDDZzP4iaT5gjJnNzslWPidJywGPm9nLaX0+YEkze7BFORbF713+Wt5QIrcp8C5gXE5uv9z+ycBBeCyhvEyT0pH0ETP7U2Hb583sqPR/JTO7S9IaLc63rHxXAVcCVwHX5K9fVSSdAXwQ2AOYBTyVzmUF4APARsAP8NHWo4A/tpMzs0sK6a9H83P725JyrI+/N8smWblo47WUdCWwNO62fCVwlZnd2sN5z3kW0/qq9L2zV5nZzd2mWZZuq21p+/rATWb2oqQdgDWAQ83soZzMfsATwO/xa/IJYDxwL/BZM/tAkrsZOAq/N69lx5vZrF7Oo1dGmkKfBXzSzO5O6ysCp5jZe3IyZwG34YoffATrqma2ZUl6fwaep/km/Lwgdy3+0hblzkr7H8CVrkqK3fRSpGNmAFsD55rZ6mnbbWa2cvr/HjObJWmDsmthZleUbW9H9mBL2g1XEIuZ2fJJMR5lZhvlZF/HB4+9mm1qdU6SZgLrmcf0IY1LuMbM1iwpw/7AzsB99H2ozMw2LMgdBcyPK6vf4NfqejPbNSdzNa7sDgE2B3bBn+kflOR7LfBdM7ssrX8LeL+ZfSStH2Nmu0uaXnLpmsqXjnkbMBVXROsAr+DK6KslabRE0p3A2cD6wFLAS8CdwIXAmbkP5TuBT3WSy6V7ErA8cBN9z62Z2VdKynAX8FWan/GnS2TnAdYE3g98Dq+UtK0AlKRxY+653wOvMJ2ddn8cOMbMDs/JrwMcDrwDmAd3lX7RzBZK+z8CbAJsC5yWy2oh4J1mtlZJGW4BVgVWAU4CjgO2NLMNcjLXmdk6heOuM7N1JN1sZqumbbPyemjYGI7hqb0uwC2dtuFf3KJM07a0/baK+ZYe389zmZF+b8xtu3mQr98N2fngL0U+71sLsocCNwO/whWWurk+rc4Fj+UzT9V7nftdELi4IDOrWHZcoZaltzhwXTqXA4GzgLElcuOqbMvtWwqvtR0J3AH8udf70kFm44ppbZz7f2e7+1b2PFaQmwp8G/+IXJuej+37c87ALcACufUFSt7rmXhr5EZcme8CHJjbvyqwE/BQ+s2WLYFF25UB+D6wa9m9SM/Mlrn1LfPvLrBYWvYFvpCeh2zbYt1el/4uPQ8sGiZmSjoO/5qC11aKTZr/SJpqZlfDnGbVf1qkd62kd1vnJuP5kjYxswvbCUl6X9l2y5mEcjySmsOWajxfwV/ALK1bKTG15NJcpUOZS4uYfl8xs/9KyvIaU8zLzPaQC7yfFKdH0sXAr83sgUK6T0n6qJmdm9LbgtaBiW4DFgGe7FDW7J69JOmtwNPAcgWZlyWNAu6RD3L7B7BEWWJm9i9JHwX+gj8zW1t6Kwtcize9O21D0n34ef4er9192cxe73BevfIT4JKOUo1ytwFvAR6vcNx0ST/Fa8mvZBut2dR0Ba5cDwIutNQq6wEV/r+WW3+tsD8ry72SRpvZa8AJqdWV7bsZuFnSyWb2avHYFsxOtvwdgPfJQ4IX++V2wJ/936T1GcCOkuYH9sSfpXzr/Bv5IgMD0udQlZGm0P8P+CKu/ITb8H5VIjMt2dIBnsWb+GVMBXZOJpNX6LMbFpXlHsA+kl4B/peTW6ggl7+Z4/AQw7OApuY68Hm8Frw0btq4OJ1bxmYtytwSSduY2Rltth2afq+QtA8wn7xD7gvAecX0ksKbLulGvBa6P3APcGzJuZws6Qj82jwCfLpFMQ8CbpR0G42Ko9gncL6kRYCfAjfgL8dvCjJ74maZr6SybYjXyvLnP5vGj9U8+Eu2taQ591DSW/B7MZ+k1el7QRdKeZRxGP4MbQ+sjl/XK83svkIZ5jWzV9pse7BF+g2HVJApyi0O3CHpetpfa4C10++U3Daj+dl9M27yeR/wlWSa+6uZfa9i+TLyz+kJwAxJ56T1jwHHF+RfShWfmyQdjH+k5jgUSDrdzLbFn62yPqeyCtB2wCfx2vk/JU3En7f8cfficz6UcQXNlYxhZUTZ0Dsh6Swz2yr9XwjAzF5oI79s2XbLdYr0szzLAAeb2fYDkV6F/Cp1CKVa7a7Ah3AFcBEeOdNyMgvg8e23wzuBzgZOM7NH2uS/IP5MtewclHQ7cDRwKzCnNmtt+gTkndfjrKRje6CQtBP+4Z+C10AzZgMnmtnZZcelYxfETQBfByaY2ejC/soddW3yqCSvxo7vAet/KeTxDmAD3Hy1HvCwJbuzpG+a2cFyj6oyxdpkv0/HrYF/HLOK2u352n96V5/AP8hfBRYGfpUULpKWMrPHq7zTSh3g6X/Dx1bSOmZ2XW79rXhFaGradCXwVTNrCEQoqamPDu+fu9XMOrVGB4y6KfQb8Wbml7KXP93g4y3X4Vdy3BI0ekk8XCKzKDC5IFdmSskfI9wW+O6SfQcDB+CmhT/jNsA9zex3Bbm2nUFJpusOoU5IehGvjZ+C9+gXTTJnS9rBzH4n6WtlaZjZL0rSvcJynU5t8h8NbEqzh8YvcjIr4q2iZQsyZR2Ywk10y5nZ/ulju5SZXV+Q28pSZ3eFMv4cf9EXBP6Kd5xfZWb3p/1Zrf93eE0wX+s/ysxWqpJPSqtrhV4x3a7uYTIz3Q1cjZ/vjILi3dzMzksfyLL0puVkv2dm+5eUaWHgj2b2frmH2Xgzu6MgszLwhJk9lds2GrjIzD7Y4ZzzH72it01x/SLgTCDzDNoR2MbM/l8hzQuAdYGsU/39uP19RdzL7iSGgJFmcumE4Q/ajPSALo2/8HuVCSeb6s+Bt+I23WVxO/a7CnKfxc0uE/AOxXXwF7jomZGvlYwCVsM7Fsv4kJl9U9LHcZPLNvjD8LuC3BG4ueMMvPb4abxzKM9jeK3yozT2KczGazNZ+bqxy5+RZFdKS4MoXmPPmrxvapVmCbMkHYRH5mxnqz0PeJlCTb7AGbir2LE02mDL+FVKZ0PcPPNvvCOzwRPHzM5SB3fJHNfhLbAnWuT5//Ba/wQgrxhnA/t0KG+RB7uVq1IZoP09LHtWJrfrJzCz89LvtFYyOd4r6UAz+06uzG/BW4xZi+hw4Nclxy6NX8NP5vJ+TdJLkhbu0Jor2u9b7QN3v82bGH+T+muKvA68I3sWJC2Zyr02XqsfEoU+pD2wg73Q12s9Fbd1Pw68pY38zbhN8Ma0/gHcXaoodyv+ct+U1lfCzQ9FuXzv+qeA9dvkfXv6PRaf+QlKPENIgfLJ9foD17ZIcyz+4q6clrGF/cu2W4boHk0vWS4rkWvyaCqRmdXDs9HWqwj/QPwW7wf4Qbr3x7VIcxTeafa9tD4RWKtEbqsK5Zsf+B5wbFqfDGzWq1z27NDsGfKjFrJNz2qLbePwvp5f4Xbu4/EWcLb/PPxjXbqUpHU+8IvcudyLj8doeE9alLnJSw04HXgY76Q+LFvKnoXi/xbrl+EVKqVluxbPa9FLTFn58s/cYC91q6FLPhXe9/Ca7CrAhZJ2sfKBCv8zs6cljZI0ysymS/pJidzLZvaypMzmdpektxcyHo27jO1QsaznyX1//wN8ITUtXy6Ra9sZVGA9XBk9iD9Qy0jayZJpyLroG5APtPi9taiNSVoe+DFtPCisxF5qaSBGBf4k6UNmdnFJ3pnP83mSvgCcQ2Ntv2kgF/C/dI8spTGe8pr/ema2iqRbzOyHyazSyn5+JI21/tm4O2TR/35lSe8qbMMaa/0n4K2rddP6o3gL5PzCYVXlsjxaeoYUOJxmT56ybScBd+Gtj/3wisuduf0/a5F+WdleTi3UUyWdip/TnmZ2Tk6s3Wjwsn0XpKUdEyQdhr8j2X/S+tIF2c/gH68j8WfnOrz/qchVks6nr7N3K+DK1Bf1XIfyDBgjSqFL2sPMDm2z7Vu4x8ZU846IU1LP+TTc/FHkudShdSXupfEkfQNp8jwq97j4A3CJpGcpzM5k3twbL2keq+DKZWZ7p4/HC+nYlyifZHtHvHb1Jdx8sgz+sJTxC9yU0zDwCnhPWi96fGSUee28GfcYmEXzyMQNcHe9GXhHVVdUNGlcB5yTOnCLnkW9uIodhiv+JSUdiA9U+m6JXPZRbecumbG2+UCtG9M5PJs+vkX+nfs/DvdgurMgs7yZbSdp+5TWf5Ldv0g2ftPoAAAgAElEQVRVuewc2lYGJK2LVwTGF+zoC+HPXZEVzGwbSVuY2TRJv8dNJKTyVO5wzeV3PfBN3Ca/XLbd3H5/j0pchlO/0f0lyd5mhdGZkjYvyOSfl5mFfQ3r5qOdN+l8NnwRfy/Xx5/L3wJnmVfRq1Zi+s2IUui4KePQwrads22pNtdQozOz6yW16hTcAn+Bv4rXNBbGax0NmNnH09995SMJF8Y7Mos8CFwj6VzgxdzxZZ2D8+MPwUR81OZb8Um0G2pauVr1f4AftjiPjLGZMk/H/l25eDdmVtnWbWaHyt0QN8Qf0lVSGe4EdrSSjuMqqMUI0BLRn+M1tlvTS5Ev23IprXHWPDpyHCWY2cnp47QR/sJ9zMyKShW81l90lyy6aWZUqvVb88jjn9E8u9d/5SETsrSWJ9fq6EEOvDIwivaVgXnwTt0xNNrRX8DvTZH/pd/nUsfkP/GO6wbUN3q6AWscNZ3P77CSbaRyny9pW/r6h6bgz0aZa++xqVV6ayrH9rh76xy3XKtg35d0SFn5c2l8rbBueOfpmZ3SHkxGhJdLuimfxG3jV+V2vQl4zXK92umF3pXmGuBnesh3ITN7QS3imhSb9pJ+0EKuSRFLOg1/QD9tZiunl/SvZrZaQa6sI/N5vCZxgOWGZks6PsnmB16NMbNdejmfTsjjzCyP2z3L0mvyd06mjFVyvwsCZ5vZhwpyFwEfaWXySTJduQNKmop36p2QlO+ClhsklVoD65jZtWm9rbukpE/hNtU18Fbg1nh4gTPK5HPHLYqHMZic27Yx3mJ4J14pWR/Y2cwuLxxbSS4nPx8wMf+hbyG3bBWTnNxB4Cz8A38C/jH4vqWYODm5N+dWx+Gd/ouZ2fc75VGS53fxQWMrp0234+bAJhOlPBzDmfizPxU3vW6Wv4eSjsHt6reVHL8Afk/XwVugpZjZcYXjqnRADzojRaEvizd7DwL2zu2ajXeevZqTPQO38X2SnI3PzPbIyVxtZlNLTBANpgdJ55vZZiqP1WLWHLhodTO7seI5zTSzKWqMaTEnNkRO7mDcg+P3aVPWQfM8blraPCc7L17rz/vz/sqSn22351PhHDbAa6+7le0va35Lut7M1pJ0HT6M+mm8mTy5IHcibjr5E4328V+oB3fA9LGdArzdzFZM5pQzzGz9gtxfzWzd4vGtkLQSfbX+S8tq/YWP8mjcr39/y8UqSXJvxhWJgOvMrHS0bRdym+M27XnMbDlJq+EudGUf2vG42aNYESobFNcT2XvX5THCO79bumJKPkIst74ibh59BG+J/acgvxruIfNu3M05MydOxp+h4/HnqFXLp6wMMynxRrOcB89QMCJMLqnm8BCwrpqjBM6HK/aMtja+lN7U9NvWBGFmm6XfqqPBfiFpKfymnmrt51it2nRev6B0bpV0jZmtL++4zJf3lWQmuSSle7eZ/S+3v9vzaYuZXSHpxW7splQ3aTyQlnnSkqcXd8CP46M5b0hlf0xS2f2/WNJWeKuhZW0n1eZvMQ+mdlcruUTeNPAq7j/d0Fejvsh/F6T7uo+khsh/3cgl9sVHK1+ezvkmtQ7DezI+hmEzfOTvTriiy/It9VNPvIIHW7s4a1GpMWrlKFzJdePemjEdt+9PzJv55H0DU1M5p0vai8bK2WL4x3OGJCznkmtmNwHbptbhFDz+yn/wil9DS0bS4rjbc/FD19CiTNuqdkAPGiNCoWcoFyUQb+pPwN3M8oOGOtr4WpkcMspMD5KWpnkAy5WF4z6Qao/bAsfIR6ueZmYHlGTzA9wOv4ykk0lN5xK5BSWtbWYzUjnWwpu5UOjAVUl4YeW8XAqyXQ+UKknjdMBamIUaXqIkPwqvxT4HnCX3Cig1aZSZqXL7puHhHSoPAgL+a2amNCxcrePQfw3vOHxV0suUdxhjZq9LurmoaFpwgJntmN8g6aTCtl8Dq8rDyH4DryX+Fu+Apgc5gFfN7Hm17DNt4M1mdpzcyeAKPIxB/kPdThkvir+Dn8GfffA+kDnlwD/O29I9Hwb+jjs4LId7jMyHfyQuBg5JH6rpbdIoxcz+TfrYlSGP3LoA3pn+cbz1uxOuU4p04402eNgQ+UcOxEK1KIGfxR+wDfBe8CfJ+bUmmQfSvgdwc8a/8Kb/a8ADJfn+BFeSF+KdK+dR8KktOebduC37v21k3oyPhtwMWLyFzJq4L/QDqQy34LWuBYBtC7KzcJNCtr4iJb7a6Rrdise5mY7XTpp8ayvcj6VwH+fKfu14P0GVtMfjtfgLcV/gy4plBObFTS774BHzvo/bc8vS+zoecuB+3ET0VzyYVn+ex8vwVsGltPC1TnJF3+YxwB1lMrSJ/NeNXNp+XLo+t+Af78NxU0KZ7HXp96L0TK4O3Nfl9cgiY44CtuvPtS2km40TGZueuUVKZBZNv8sD86b/78fj/DTJV82Xvoie2bkJuLxEdlm8crQQXln7BW4tGJBrULnMQ51hP29sQ8jZ9GJ0HIDSJr2jgE1y6x8Bfl4id3f2kHRI7x14M/c2PHDP/wFLtJFfGncZe1+2tJFduNODWXYtWmyrNFCq4jX8DvCXLuR/iHtatA3rite+dsW9ajbAa6I/Kcj8GTcTfBNvFu8F7NUmzY3xj8TPaBOOFq8QrNXpvqRyNS25/d/GFf6ruNfIC2n9aeCgQlpXJPl78AiJoylUVrqRS7Lz46GC/5aWA2gRChivVCyMdzxOxysHm+f2f5cWYWjT/g0L8lf28jy1SHufCjL50NBjcPfa+/BY+Rf2mO8N9H3oLsZNfe+myw/dUC4jolM0IzVlnsM7HL6M+5zfYWbfSR1At1iyJUr6Pq44HgL2sOaQr6gkKH3WWVnY9ic8fsO/aUPq6DsF72x7rIPsT/De9Nvpc3UzK3RYqeKsSkm2rZdLTu5vZrampJtwX+pXJN1kBQ+bJLsi3sxf0twbZxXgo5YzI8ndNHe0CsGzUkf0AriSa2nSyO6NkjdM2tYQB0a5CUE65FkpxkeSLQ3zYC06B5OJbS38uv/NzJqa45IOMrO2U66ldD6Z0rhKHvnv/VaYXagLudHAj80s73PdFZL2NLNfpv9b4B/Ol3FFl+9IXA0PS/wjS7FVJH0Pb/mdRqMLb36mq3YeL2YlcV7alPVGM1tdfZO4fBP4j5kdrpzjQTdIugGvoF2B18CPxGvgP7RCsDY1z/iUncSQhs8daQq9ZZRA+ewj65jZS5I2w5s8WVjTpmA6Kb2LcDfI3+Ev5A54bawYeOcsPHjWpTR6XJRGjqt4LncDq1iHnnRVnFUpybb1csnJnYMPA98Tr1k9i/uwNw2gSHbUbwBHW8nMSmn9dFzxXULjy9uf65PNCnMR7qP8GD4rz/I5mWOAw63CFGhVPzqpP2BNvGa2mtyL5Ydmtl2J7Gdx08dl+PXeAPciOT7t72paOzV2+M8PjLaSyJVdyF3W6kNUBUkPm9nEwrbJ9M2YlI1LuNKaPUmaKlAUPKlSR2aR+XGT4JvNbMGS/a3KminyGcAv8Zbj5mb2QNUPf0malT8E6mLGp8FkRHWKmndETcP9QzMvDuvbbS+l/1vi8Tdm4cGgvtAiye1xe1c21PjKtK1IZh9ti7qY4xK35Y6l9aCQjAlm9uEO+V5qHk1yPzP7Fo2eH01Y9YFSAPObD87KbyuOpq0y3Lqs3Mvjrl7bl7xwB8ij7u2F234XIhdoLFE1nj2kQF+SOn10OoZ5yPENYPXspZW7E15LXyzvr+Gd+E0fX2iMNV7S4b80zR3+leUSN6YP2RmFc24ZCrhA2SQT9+DmnvIDpMPN7MtWwZMqXymRexztgXesnkr5NavCLriXzoFJmS9Hc8C7LM8F8Fp85pkzCjdJZXrkW5LK3qXn8RhL+Wf+eSvMWTscjCiFLh8yfhRuGxOwnKTPpQspuRvSS/jDnZ/4otXowWfwh6gt5u6PVQZonEDfHJcfIM1x2UL2JbxHvFOtv8qsSkvJfcI/Ko+J0ZBnviaoRnc7rLPL4b+S4s28Q7amOX7L07idsuNsPXK3zk/gH85V8A/g9gWZ0XgN9Hz85Wk1dLrVxANl5D86WSWg7N50DPOQl6XRZXY27vvsmZjtnpXTOo9o/SJuupmRjr1HHta5SFU5cKX/NI1RQY3WsWmK9NJ837Sdx0mJqWIx/MP3KdxDaw0ze7aHfJXSvwPvCM3yewCPOVTGpfgE3ZkpdX7cVr5eOvZiSdvgFbRsBOiWeB/ZFyRtaGZZK6PqjE+Di80FhvyqC+7vu0JufXngrvT/M/iIxRvIzeuIm1wubZFeR0+KJLc53jH6QFpfjXJvhm7muNypbCmRuwP4b8r/FrxDszjf4tb4AJzZVItkeDL+capyzd+G20dfwkfrXQ1MKsj8Dv/IHoyHEC1LZ7d0ff+Od86tQolHUU5+ehfPxRJ4CIWJxfPCwzt8Mbd+PX1eTtt0SHcDPCTxPIXtX0vLb3FPiH3xD/kNlHiR0MZbJbdeqcO/qlwX1242fR22+WU27vbYbXpP4xWbC3BT3llpeQb37c/L/jQ9N9/CR+12SnsqsEv6Px5YLrdvsfS7Pm76+zt9nmz3t0iv4/zD6Zkdm1sfi38IxpCLBFny3pW+e4O9jKgaOvCkpRlKEplbImZ2fLK3LkFjDPJ/4jXlMtoOpsixL80DNMqalN3McVklXjRUqIWa2ZnAmSqZMEAqdUJeCrhdPjVZvineNILQfLKGD6bm6SgrsdWa2Q5yn/vt8QEVhr/Up+Tkj8RdBT9pZjNT2drVAK+VD5IqdqrlWxtV4tl/E28RZMyDBytbMJXxjJRWWViErFW0gKTXzAeMQJ9P9n1pyfhj/gTU3bR2V6jCtIBdyCFpAm6uWh/mzBWwh5k9mslYF/F9KvKQme0iH2PwTjN7PJVlKfwZyLMXXpv9LvCd3KPa1FGu3Ehf/L6NxSsS66fzyDpbj6PElt2CFyWtkT1Tkt5D8/zDS+N+79n4lvmApc3sVfmUlKT8hywAVztGhEJX3/ROt0u6EI95bHh8iL9lcmb2D1yJZsfta2b7tkm602CKjLIBGmXKqDjH5QcozK2pNPehKg7GMbOHVBKDpMX5NIQTTR+Xk/DmbJ5OQb7yaeyBv0Cz8cBHawB7WyGsbVKGZ+EP/J74QIxvSDrMfIj7W/H79Qt58P/Ti+UtsF76zXvzNNid8Wu8Du42ubqkD9DcBzKPNU6bd3V6+Z9R4+Ci3+Mf9mIkx4wFJR1rZvtYYdCTpAXM7EWayY9o/XkuzRdoHtG6N97hfyvwObzVWJxDtRs58Pv2e/y6g3f6n4C7bw4W2TlOypR54gl8XMQczGxUF+lWHenbjS17T+AMSZlJbSnc8yzPL+gzjQr3bf9penYuVw+zdg0qQ90k6GXBH8JWy/FtjisdcJHbX2kwBRUHaFDShC9uw6c9g4qDcfCm/HnA39P6W4FrWpzPicC30/958Y7cfTtcg8Vp4xNOmgQCV07n4t4+RXPB5njH8i14R+ESafv8eI2tmOYEfKDPLLxGXTrpQoXnIpv842a89QAe9Covc2+b4yv7E+P+3ncWtq2Lm8QeTuur4l5FxWN3KNm22EC9H23K3NGk0EOaK3fYv3P6PSK9VzvjLd8/4R5JveZ7ffrN/M0XoNwk9WPclLMuHjRtDdwu3yrdsbjv/bspTAhTeF63wk2byxT27Z5+f1C2DPY9birrUGc4pCfXYaYQygdTfLRELj9AY2b63zRAo6joWm3r8hxuwmsG+dGxpTbTJPd7fODJxfhktvn96+Bmo7Pxj9dtuEnqSdKsSSVpZiPkDgU+nr+u+OCNqbgt+X25Y96Lx+0G2KjD+b09/+CTBvyQG/lJi1GguG1/QfwDe0oq47UFmZOB3Ury/RxuEipuf1/Z0qLsM/CQtPl7UzaLzgX4eIBs/S0URvBS0fZbVS53fXbAP0aj0//S/qQunser8X6IL9B5oNvHcQeBQ7Jnpx/5VhrpS5e2bPzd3xZvSX8aj35alFkY/zCsly25fT9Jv237Y4ZqGWl+6F2FxpUao7ANYrkqT9Ks7iaZQH3RCTM/2wXwgS6r5GTyfs5j8Qf/GrxlgfXZCGfiTf2FgWNw74vr5L7Wp1iJz62kE3A74nJ4DXQ0PvT5PclOuo+Z3VI4ZgqupIsTC3Qkd555H+U5k0Lk73XmdoYPNc/i2Z9sjSGFl8A9Vl4hNddxG/q8eCS+hgk65CGB8/muhSvfsomnZ5jZ2uocMXM3vAW4Ff4BOBf4uuXMVqrox1xVLslOxGvK6+LP3LXAV6zHWPa5dCfjTgjb4Mr9BDO7pERuWSr4y3eR78bkxqCU5dllej/ATSjvxE1XH8FNclvnZD6D2/qXxs1c2RiF96f9t+LKfoZ1MTn3oDHcX5RuFrwDa3+8I2onvBZ6aEFmAt78fwq3252F+3KXpTeNXC0DH/LdZMLBO2POxhXCLdmS279qKs9DNHqtbEmb4dIVz7ljzYTyWklT7YRcc5tm80FpawZXlmtk1wmPP7NK+t9UG80dVzocvcL5tirHvPhLnK2PpruQAxvio4u/DGzYxXHLUFKTT/vOxGtsN+CdrV/Ho2yWyX4RN53dSq6Gl9s/o2J5Osq1et7Tvs2r5FMhj9H4B+ofuNnsLmDL3P7d8BbtfWl9Mv1oHeAfkMkVZTfFO8M7xfe5NT3fmVlxSeC8Epn56AuT8a7884Cbd56nMbxD5iX0wkBc666u01Bn2M+HKGvqZ2aAsTQHbLoE92oZk5adgUvapVdh2924+9pytLd3l9rgOpxTS5e7nEylGCQV8qo8OW5uu/Cm+vfT+pyJkGlvn265r2oZC9sXBe4pbDsXWHiQnznROlbK4rhJ5wncbPU7vKM92/+13LIXbj47KdtWSKuS7beKXHpeJ5Ucuwv9jEOCu5segpt8jszyxvt2HsrJdQyk12W+++EuhPfhHepfBlYrketmku/MLj8Lb02LwqTUeIiFOeeT/pfpiD8O5nNYdRkRXi45qkx/Nd7MTsitnyhpzxbpjZK0qKWBDMllreyaPGVmHUeKAv9P0v70xXMoNaOkvKq43IEncAk+yGVx3M+3FEk/Ag42D0+LPETuXmaWzZ25qqQXUrnmS/9J66WDr/ABWtlEyPvROBHy3yTtZmYN8cwl7UrfdGE9oRaTQhTEqo7+7Cbfw3P5jsL7GsomGMd8YomiB1GeohfGOS22A6ydfvNxhIxGr56qcl/Fn5dNzEd2IunbeMf+Bm3KW4Uj8Pj1+1huuL+510l+jtZXzOy/mWeYpDH0NlApS//7KZ358Nr/N/Ah/sV5T7uZ5HumfBDZsfjz+m/SdIiSxpjHrH88yZwHXCTpGUrm0TWzsvmAh5yRZkPvOP2VpL/g3h6npE3b44MRmoZGS/o03oF4Jv6wbYsPGT6pILdRSqc4qrM46u1e3MzSNA9mSd434y9hg8udpdGF8imtfowPyNgfr9ktjiuZT5tZ01B9lcSeUJsp2aqQs2k32YmT++E5+MCn/HyP8+CdYGVxozvld7aZbZnsrxmtJoXYKbeaXW9ZdR//svyzNC3l+6ClKelyMnml30R/PigDRXpmjwY+hsdGWROfiq2XUZi95N8ykF6P6X0X7xBeEB/MdTU+aO/xglzWr5HNiPUM/j5OLqZZOG4SsJCl/qCy9yZd04WBC6xvFrDi7GfK/5ZV5gaTEVVDN7PM3/YKymd2B7e1HYE3C7OOoNJOUzP7beoo3BC/AVuaDx0usgseYnYsuciINH/5H8HtylW+kv8zs6cljZI0ysymyyMwZhxBXwfmZRQ6MCmPvTJaHn8ke9jmw23P/aHlRMjmHYrrpY9RFovlAjO7rFVi6XqfgM8J2aRczCwbc9ByUgh55L8JZnZk2n49XoM3fNRh17RLU9I3zQdvZeRnhv8h3rRvl/Z0ysccbFiQ25TmDv+yqJod5czsUkk7415N1+LeRk1zcHaLqscr6sZfvgpb4h/YC/D3/7oW53N+qlEfTF8loyFftQmapr6BRmVxbC4tyW+BtG+gB2j1xIhS6KoQSta8B79pxGNJWvmYJmVKPM+qZvbuCkX8JnChfHBSwzyYJbLPyWPPXAmcLOlJGoNejbHkBSFpPzO7LqV1l1rPQPM74NLkmWL4h6zn2mriMLwWvoSkA0kTIecFzCzrgK3CJ/AP5N9yyv3iko9gg+kpNdmzUMeVRn92Sac05yj0fAtAHmK20zX+eu7/OPwZLrY2jsLdYz+AK6CtSc3/buUKtcV58dhGT8ofnP7WGk+gQrwi87g+x1I+vWDXpFbim3A32Y3xQW5PWJpOUtKawCOWRkqnd+tWvLP2kEJyVYKmjVebafdy7/RcZeIYUQodH1qdhZIthoTtqhls3U0hdp2kd7aovec5ELfDjaN5HswiW+Aud1+lz+UuX8vKB7oqDkcuPU8zOzjZnrNJi/c3s4vKZKtiZidLmpVL82NWMhFyF+ndiw/z/h7uing88Lo8lvuheG0uG9qe2fvBzTrHpP9VR392Q69pdnyhzaN+5rlGzSOSq9p+O8oNcm1xvlT7l/ncA/tKuopCK0XN8cGzj0lP8cFTn9l78T6AKXhr+KqcyNF4oC0kvQ83V34Zj7t0DP7hAy/E7qlC910zu6ZFlqPxj3mn+fuWqKj4h4SRptDbhZKd2WJ7O8pimlhJB8dUYCd1DtO6mJVMHluG9Q0Vf13SBcDThVpqLx2YmA97Hugwnk/gL8+YVJY58S96QT5Jxi647/5ZuKfIVNxjaTXgILWfFGLR/IqZfSm3Or7HYg1GmsCczvaMUXjN/y0Fseyj/ZKkt+Kd32XxgqrKDRZV4xV1E1OlCj/BW7OH4Z4n/yvsH2198Vy2A44xn2/2LPlELg2kCt3PcG+hMh4vM3eVUFXxDwkjTaG3DCXbY0dYPiaHcKVSFg+9bTzyHH+R9CErxDnJ066zU9Kczk4zK/bedySlfTg+Fd48+MP2Yn+a2HKvnZ1xd7Hsg1PmfVE1vVl4Z9lxeEyYrKU1I9XqMv6UaloNmE9kPUPl3jWfo8RMUZHKaapxcNj8hY9tmUkjHx8mmzB514JMZvv9Ke7XbpSbK6rKDRbFeEUb4mMuigxofHAz21Q+CfNKwEqS7jaz/+ZERqvPM2Uj3KSS0UrPXSxpKzwKZLGlVVVBV1X8Q8KI8HJRnwvbGHyAwv20qCnLR/oVT+p5vAZ/dLEjRdJquDvXtviLdrZ5MKlsf0P88A7lzKZX+y99LpYNL7h6GK1ZlZT2J3Ab8hTcw2AF69GzIKV5N/DuwsvTM5LeZh7BsZNcyxGb6nL0Z8VyDXiavZL6isZZ59mVKskNJbmOxm3xCsWAxAeXtAluVpkzFwI++fuf0v7v4C2+f+FjJdYwM5O0AjDNzNYvSbPldIiSFsvV+NuVq6fp7QaLkaLQl223P9nyMtlD8SZy5ra4He6vPh/ulrSjfJ7MbJKFp/Hh+l83s9J8JJ2MB73q15DplNacuTsl3Wlm78jt69fDoTQfqhrn4bzWzNbrdGybNM8C/s/Mnuw1jZROSzsjdLY1SloG97HfPrdtQ/o6T2+3Nt41XZRzwNNM6a5Hc2f+b3P7x+GufVPpC3X765IKSCW5gaZFRWkOlkIvq83kFi7W25R48pAHm6U+GOSTrlxgZivlZNbBzagXZybN9K4v2B8TYYdyVVL8Q8WIMLkUFPYa9D3M15TcqNXNLN9UP0/SlWb2Pkm3p2134TbhzXMPSHF6szxVbe3ZgKEs/8vNZ93J03VnZxe8lJqlN8n9gB8nuVX1g4Pwqcxuo7Gm1dGTqEB/O+oepc81MitDNinJgDEYaUo6CZ+M5Sb67MmGj2jM+C0+aCtrHW6Pm+O2oZGqcgPNz6oIWYoLLmlcycfozf3Iv+VcCLm8ryspz99bJSjpTLxT/s9WYbatMuYmZQ4jRKFnyGcJ34a+Xv0TJJ1huRnocXejOZ4r8gBFi6d9mdlgK7yGPl0+CXPTtG0FKtnaJf0YH8Bxctq0h6SpZrZ3Tqynzs6K7Ig3c7+Ed0gtg59rf5iGd0jdSuPHqCuSR8ZoPDhU0Y2sCTWP2FyNFiM2RwBT8CBt7T7Yb7fGoF7T5YPPepUbUKzzVIVFzpK0RbJpI5/s4wL6XE8roYpzIfTIUXjn/OGSzgBONLO7+pnmsDIiTC4Zku7Ea+Avp/X58NgfebPFJhTmHcWbqJfjYVR/mZNdAB9Jtz3euTMNOKesU7OTrT3J3ILHl8gmnR2Nx30om7R4RCDpCjPr73DxfHrTrcLsLmocBZqN2GzlYjZXk5TFV6wwqrEgcyIeY/+6tL42PiXhF3qRGyxUcWCRKkSYrJjfCW12m7WItNplHgvjOuA7uDvkscDvrNmTZq5npCn0P+HD47NYJYvgF36zgty8eG+48DlHO9oX5a5l2wDbZXa+HmzttwDvz5phKc3LB1uhq8XsRxn9yV8+6/kr+As5EJ1bB+IdwqVTy6nauIARRbIrr4Z7y5SarVJl5e1Adu4T8dg+r5Pr+K8qN4jncjV9A4s2Jw0sMrOm0bKSvoh7iE3COzCvLcoMN8kMtAPeun2MPhfad1sKkTuSGGkK/Q+4SeMSXIFtjHcKZfOKfiXJte2A6iK/13Fb+645W/v9xdpITn573CVxOv4xeR/emXpqt3l3Wc7KncY9pF3WydWfzq226SkXQ0PSWWbWX5PRsCOptIWTN2NUvYeDea+rIGmWeSz8Wy2NnpZ0lZm9N/3Pd34LV5S34vFXuh5oIw+7cLBaDBy0/gViOxuv+J2Ex3T/Z27fTDOb0vLguZQRZUPHh6Cfk1u/vChQsQOqKl3Z2s3sFEmX4x8dAd+yHgJUdUvZS6wUmbGD3bYtcpfNX5vZ6f0pX54K5pb89e1pVOHcRhX7c05hL0GjKePhXuQGkU4Di7qJMFmFbFRyLwMHS5GHCXgUOMLMLkvmvaMlPYRP2fjMSFTmMMJq6FVITdJOHVDdptEDSeAAAASNSURBVFnJ1i4fGHOTmb0oaQc8VvWhQ1Br6joyYxdpX1nwGuo3ahNcqlBD71ekyOFGXcxOpRbhlM2sGNOmktxgkZThncAi+LO2MO5O2uRhMrci6Qbgg2b2jHzw2qn0hQl4h+VmLBppjAiF3sFGbPle/yodUP0sS5OtPbfvFnz2olXwFsHxeATHAetUbFGmwRys9D3cvbJo8+7JXUstgkuZ2a5p/2spH+FjB17KDqX/gaXmWtQhnHK3csOFpLbzBliX7q6Sfmlme6rcD97wSszR3XxQlJsmUNKR+HwH+6b1OeNERiIjxeSyWck24dPN7VPYvjhwh9xnPOuAMhugAPRJkR2dliKvmpnJQ7EeZmbHFbw1BoteIjNWJfMi+GJum9G7OaRtcCnrIeRBTegUTrlbuQGlC0W9Lu4pcgo+iXZ/H8BsboJf4ZOSv457sGVjOBbHK07v7CLNXsIEjAhGROGtcWBR0X3wrIL4vrn/7eKzDAaz5TPD7Ai8N7ktDsU1HrTBSmY20IGfhju41NxKFk75KsrDKXcrN9BUVdRvwZ0Vtsff0wvwVuLtLeQ7cYt8kNxncM+erCJ3Ij5r0v8kdRuW4hTgCkn/wp/HqwDkYQLmmjAKvTBSTC7dug929BkfpHK+JeV7vZldnexzJ5jZ8oOcbzszxTgzG9uPtD9dtr0Xr6GU3vfwUY4b4XNSGvAbM/ter2WsA5Lmpy+eyA74HJcnF01bVeUGoXyj6VPUq1BBUSf34e3xQGL79fIOSjoE71D9qpnNTtsWwkeuvmRmraaX7JTukIcJGApGikLv6D7YrdIfxLIOy8dksEjuYhnjcEV8w0B0HGkuDC411LToOM1qvy/j5oXv4IHDOspZ+aw6A0onRZ32b5pkJuFjGI43s3/0kNc9wIpFJ4f0gbnLOkwt90ZjRJhcqOY+2G18lgGjxcdEFVz05nrM7Mv5dfmoupNaiLck8ydO/7cxszPMQ+e+IulHZlbsC3lDYG0mo0hKa2W8Bl5JjkK8m4GkRFEfRmFyDUnTUhn+BPzQzG7rZ7ZW5rFmZq9Jmvtro0ONmY2YBQ809SngfNys8GvgQ2nfx3FFmg3d3Qh4YIjK9To+z+EKuW33D/f1GqRzHYu7yXV73A1l/8vWY2m6dp8bSLkeyzANj+t+ALByG7nX8eBhs4EXcsts4IUe8v0D7npb3L4DcO5w35u5bRkRJpcyWrkPVvUZH+CyfByvoa+HT958Km4XHvGdfQV3sVG4N8Hp1hhwrEo6c0IDqxAmuLgezH0ks+ecSKP5XQyiO6mkpfFWwH/omyhkTbyv6OPWgxmnzoxYhV6Fdj7jg5TfkH9MBhs1Dlt/FXjIzB7tIZ2WA4ZG+gCiYPBRX5x64XHqB72vYCRSa4U+nAz1x2Qo6E84gcH0xAmCwAmFHpQymOEEgiAYHEKhB6UMZjiBIAgGh1HDXYBgrmWMmV1sZmcA/7RcOIFhLlcQBC0IhR60YjDnPg2CYBAIk0tQSnRiBsHIIxR6EARBTQiTSxAEQU0IhR4EQVATQqEHQRDUhFDoQRAENeH/A/0IPZ1bWQaWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The maximum number of different character for one alphabet is 55\n",
      "The minimum number of different character for one alphabet is 14\n",
      "The total number of different character is 964\n"
     ]
    }
   ],
   "source": [
    "alph_num_char ={alphabet:len(os.listdir(f'{PATH}{alphabet}')) for alphabet in alph_type}\n",
    "num_of_char = alph_num_char.values()\n",
    "\n",
    "plt.bar(range(len(alph_type)),num_of_char)\n",
    "plt.xticks(range(len(alph_type)), [alph[:10] for alph in alph_type], rotation=90)\n",
    "plt.title('Number of characters per alphabet')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nThe maximum number of different character for one alphabet is {max(num_of_char)}')\n",
    "print(f'The minimum number of different character for one alphabet is {min(num_of_char)}')\n",
    "total_char = sum(num_of_char)\n",
    "print(f'The total number of different character is {total_char}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of different pictures is 19280\n"
     ]
    }
   ],
   "source": [
    "alph_num_char_ex={}\n",
    "for alphabet in alph_type:\n",
    "    char_list=os.listdir(f'{PATH}{alphabet}')\n",
    "    for char in char_list:\n",
    "        alph_num_char_ex[(alphabet,char)]= len(os.listdir(f'{PATH}{alphabet}/{char}'))\n",
    "\n",
    "num_of_example = alph_num_char_ex.values()\n",
    "\n",
    "plt.bar(range(len(alph_num_char_ex)),num_of_example)\n",
    "plt.title('Number of example pictures per character')\n",
    "plt.show()\n",
    "\n",
    "total_example = sum(num_of_example) \n",
    "print(f'The total number of different pictures is {total_example}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that each character have 20 examples(pictures) and that our training set is well balanced. For our training we will consider that each character is an independent class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add label for each character\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each picture in our dataset we give a corresponding label(an integer) which allow us to determine the corresponding character. Here an integer is sufficient as we are not really interested in knowing from which alphabet an image is coming from and as we don't have need to know the character name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.array([i//20+1 for i in range(total_example)])\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reshape, our data to have the number of channel including (here is 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train=Y_train.reshape(*Y_train.shape,1)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert images to datafile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first retrieve the path for each picture in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images_background\\\\Alphabet_of_the_Magi\\\\character01\\\\0709_01.png',\n",
       " 'images_background\\\\Alphabet_of_the_Magi\\\\character01\\\\0709_02.png',\n",
       " 'images_background\\\\Alphabet_of_the_Magi\\\\character01\\\\0709_03.png',\n",
       " 'images_background\\\\Alphabet_of_the_Magi\\\\character01\\\\0709_04.png',\n",
       " 'images_background\\\\Alphabet_of_the_Magi\\\\character01\\\\0709_05.png']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train set\n",
    "imagePath = glob.glob(f\"{PATH}*/*/*.png\")\n",
    "\n",
    "#Test set\n",
    "testPath = glob.glob(f\"{PATH_TEST}*/*/*.png\")\n",
    "\n",
    "imagePath[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print some random images of the dataset, convert them to arrays and resize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SZ=64 #Dimension of the output image expected\n",
    "\n",
    "#Dimensions of the grill of sample pictures\n",
    "columns = 4\n",
    "rows = 5\n",
    "\n",
    "fig=plt.figure(figsize=(5, 5))\n",
    "\n",
    "#Print 20 random examples of images\n",
    "list_example = np.random.randint(total_example, size = columns*rows)\n",
    "pos=0\n",
    "for i in list_example:\n",
    "    pos+=1\n",
    "    img = mpimg.imread(imagePath[i])\n",
    "    img = resize(img, (SZ,SZ), mode='reflect')\n",
    "    fig.add_subplot(rows, columns, pos)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images seems clear and well centered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert all images into arrays and resize them to the 60x60 format. We concatenate all arrays into the variable im_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280, 64, 64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train set\n",
    "#Transform in array and resize all 19280 images \n",
    "X_train = np.array([resize(mpimg.imread(i), (SZ,SZ), mode='reflect') for i in imagePath] )\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reshape the image to take into account the number of channel to pass them in our CNN, which is 1 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280, 64, 64, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_sz = 1 #number of channel\n",
    "X_train= X_train.reshape(*X_train.shape, channel_sz)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13180, 64, 64, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test set\n",
    "test_array = np.array([resize(mpimg.imread(i), (SZ,SZ), mode='reflect') for i in testPath] )\n",
    "test_array= test_array.reshape(*test_array.shape, channel_sz)\n",
    "test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13180, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_char_test = np.array([i//20+1 for i in range(test_array.shape[0])])\n",
    "class_char_test = class_char_test.reshape(*class_char_test.shape,1)\n",
    "class_char_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/ validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the traning set into Train and Validation sets of pictures (Train : 70%, Validation : 30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_valid, Y_train, Y_valid = train_test_split(im_array, class_char, test_size=0.3, stratify= class_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train.shape, X_valid.shape, Y_train.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3954, 64, 64, 1), (9226, 64, 64, 1), (3954, 1), (9226, 1))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(test_array, class_char_test, test_size=0.7, stratify= class_char_test)\n",
    "X_val.shape, X_test.shape, Y_val.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our loss function is determined by the following triplet loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 64)\n",
    "            positive -- the encodings for the positive images, of shape (None, 64)\n",
    "            negative -- the encodings for the negative images, of shape (None, 64)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[:,0:64], y_pred[:,64:128], y_pred[:,128:196]\n",
    "    \n",
    "    #Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = -1))\n",
    "    #Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = -1))\n",
    "    #Subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\n",
    "    valid_triplets = tf.to_float(tf.greater(basic_loss,0))\n",
    "    num_positive_triplets = tf.reduce_sum(valid_triplets)\n",
    "    #Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0))/ alpha * 100 #/ (num_positive_triplets + 1e-16)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss_np(y_pred, alpha = 0.2):\n",
    "    anchor, positive, negative = y_pred[0:64], y_pred[64:128], y_pred[128:196]\n",
    "    positive_distance = np.square(anchor - positive)\n",
    "    negative_distance = np.square(anchor - negative)\n",
    "   \n",
    "    positive_distance = np.sqrt(np.sum(positive_distance, axis=-1, keepdims=True))\n",
    "    negative_distance = np.sqrt(np.sum(negative_distance, axis=-1, keepdims=True))\n",
    "   \n",
    "    basic_loss = alpha + (positive_distance - negative_distance)\n",
    "    return basic_loss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_acc(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 64)\n",
    "            positive -- the encodings for the positive images, of shape (None, 64)\n",
    "            negative -- the encodings for the negative images, of shape (None, 64)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[:,0:64], y_pred[:,64:128], y_pred[:,128:196]\n",
    "    \n",
    "    #Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = -1)\n",
    "    #Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = -1)\n",
    "    #Subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\n",
    "    hard_triplets = tf.to_float(tf.greater(basic_loss,alpha))\n",
    "    num_hard_triplets = tf.reduce_sum(hard_triplets)\n",
    "    #Count number of triplets\n",
    "    all_triplets = tf.reduce_sum(tf.to_float(tf.greater(basic_loss,-10**10)))\n",
    "    \n",
    "    #Accuracy\n",
    "    acc = 1 - num_hard_triplets/all_triplets\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Triplet Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triplets(X, Y, num=1):\n",
    "    \"\"\"\n",
    "    Create a list of valid triplets\n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of images\n",
    "    Y -- array of classes corresponding to each image\n",
    "    num -- number of negative images for each valid anchor and positive images - must be positive\n",
    "           if num = 0, all possible valid couples are created\n",
    "            For example : for one valid (A,P) couple we can select 'num' random N images. \n",
    "                          Thus 'num' triplets are created for this (A,P) couple\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    (A,P,N) -- python tuple containing 3 arrays : \n",
    "            A -- the array for the anchor images, of shape (None, 64)\n",
    "            P -- the array for the positive images, of shape (None, 64)\n",
    "            N -- the array for the negative images, of shape (None, 64)\n",
    "    \"\"\"\n",
    "\n",
    "    Y = Y.reshape(Y.shape[0],)\n",
    "    A = []\n",
    "    P = []\n",
    "    N = []\n",
    "    \n",
    "    #We loop over all possible valid (A,P)\n",
    "    for i in range(X.shape[0]):  \n",
    "        list_pos = X[Y==Y[i]]\n",
    "        for j in list_pos:\n",
    "            #We provide a number 'num' of triplets for each valid (A,P)\n",
    "            if num >=1:\n",
    "                for k in range(num):\n",
    "                    rand_num = np.random.randint(X.shape[0])\n",
    "                    if np.array_equal(X[i],j) == False:\n",
    "                        A.append(X[i])\n",
    "                        P.append(j)\n",
    "                        while np.array_equal(Y[rand_num], Y[i]):\n",
    "                            rand_num = np.random.randint(X.shape[0])\n",
    "                        N.append(X[rand_num])\n",
    "            if num == 0:\n",
    "                for k in range(X.shape[0]):\n",
    "                    if np.array_equal(X[i],j) == False:\n",
    "                        if np.array_equal(Y[i],Y[k]) == False:\n",
    "                            A.append(X[i])\n",
    "                            P.append(j)\n",
    "                            N.append(X[k])\n",
    "    \n",
    "    A = np.array(A)\n",
    "    P = np.array(P)\n",
    "    N = np.array(N)\n",
    "    \n",
    "    return (A, P, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'triplets_list_valid = create_triplets(X_valid,Y_valid)\\nfor i in range(len(triplets_list_valid)):\\n    print(triplets_list_valid[i].shape)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We create one triplet for each of the possible (A,P) couple in our validation set \n",
    "\"\"\"triplets_list_valid = create_triplets(X_valid,Y_valid)\n",
    "for i in range(len(triplets_list_valid)):\n",
    "    print(triplets_list_valid[i].shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(19770, 64, 64, 1), (19770, 64, 64, 1), (19770, 64, 64, 1)]\n"
     ]
    }
   ],
   "source": [
    "triplets_list_val = create_triplets(X_val, Y_val)\n",
    "print([i.shape for i in triplets_list_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a number of 28920 examples for the validation. Thus 1 negative image per (A,P) couple is enough for our evaluation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmbModel(input_shape, conv_drop=0, dense_drop=1/32):\n",
    "    \"\"\"\n",
    "    Define our shared embedding model\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of array of input images\n",
    "    conv_drop -- dropout rate for CNN layers\n",
    "    dense_drop -- dropout rate for Dense layer\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    model - Our model which transform an array of images into an array of embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Define the input placeholder as a tensor with shape input_shape.\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #CONV\n",
    "    X = Conv2D(64,(3,3),strides =(1,1), name ='conv0', padding='same', kernel_initializer='glorot_uniform') (X_input)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn0\") (X)\n",
    "    X = Activation('relu', name='a0')(X)\n",
    "    X = Conv2D(64,(3,3),strides =(1,1), name ='conv0b',padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn0b\") (X)\n",
    "    X = Activation('relu', name='a0b')(X)\n",
    "    \n",
    "    #MAXPOOL\n",
    "    X = MaxPooling2D((2,2), name='max_pool0')(X)\n",
    "    #X = Conv2D(16,(2,2), strides=(2,2), name='max_pool0')(X)\n",
    "    \n",
    "    X = Dropout(conv_drop)(X)\n",
    "    \n",
    "    \n",
    "     #CONV\n",
    "    Y = X\n",
    "    X = Conv2D(128,(3,3),strides =(1,1), name ='conv1', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn1\") (X)\n",
    "    X = Activation('relu', name='a1')(X)\n",
    "    X = Conv2D(128,(3,3),strides =(1,1), name ='convb1', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn1b\") (X)\n",
    "    X = Activation('relu', name='a1b')(X)\n",
    "    \n",
    "    \n",
    "    #MAXPOOL\n",
    "    X = MaxPooling2D((2,2), name='max_pool1')(X)\n",
    "    #X = Conv2D(32,(2,2), strides=(2,2), name='max_pool1')(X)\n",
    "    \n",
    "    X = Dropout(conv_drop)(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "     #CONV\n",
    "    X = Conv2D(128,(3,3),strides =(1,1), name ='conv2', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn2\") (X)\n",
    "    X = Activation('relu', name='a2')(X)\n",
    "    X = Conv2D(128,(3,3),strides =(1,1), name ='conv2b', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn2b\") (X)\n",
    "    X = Activation('relu', name='a2b')(X)\n",
    "    \n",
    "     #MAXPOOL\n",
    "    X = MaxPooling2D((2,2), name='max_pool2')(X)\n",
    "    #X = Conv2D(64,(2,2), strides=(2,2), name='max_pool2')(X)\n",
    "    \n",
    "    X = Dropout(conv_drop)(X)\n",
    "    \n",
    "    #Padding\n",
    "    #X = ZeroPadding2D((1,1))(X)\n",
    "    \n",
    "     #CONV\n",
    "    X = Conv2D(256,(3,3),strides =(1,1), name ='conv3', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn3\") (X)\n",
    "    X = Activation('relu', name='a3')(X)\n",
    "    X = Conv2D(256,(3,3),strides =(1,1), name ='conv3b', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn3b\") (X)\n",
    "    X = Activation('relu', name='a3b')(X)\n",
    "    \n",
    "     #MAXPOOL\n",
    "    X = MaxPooling2D((2,2), name='max_pool3')(X)\n",
    "    #X = Conv2D(128,(2,2), strides=(2,2), name='max_pool3')(X)\n",
    "    \n",
    "    #X = Dropout(0.2)(X)\n",
    "    \n",
    "    #FLATTEN X + FC\n",
    "    X = Flatten(name='f3')(X)\n",
    "    #X = Dense (256, activation ='relu', name='fc4', kernel_initializer='glorot_uniform') (X)\n",
    "    X = Dropout(dense_drop)(X)\n",
    "    X = Dense (64, activation ='tanh', name='fc5', kernel_initializer='glorot_uniform') (X)\n",
    "    #X = Lambda(lambda  x: tf.nn.l2_normalize(x,axis=1))(X)\n",
    "    \n",
    "    ##Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='EmbModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "    \n",
    "def EmbModel(input_shape, l2):\n",
    "    ##############\n",
    "    # BRANCH MODEL\n",
    "    ##############\n",
    "    regul  = regularizers.l2(l2)\n",
    "    kwargs = {'padding':'same', 'kernel_regularizer':regul,'kernel_initializer':'he_normal'}\n",
    "\n",
    "    inp = Input(input_shape) # 64x64x1\n",
    "    x   = Conv2D(32, (3,3), strides=1, **kwargs)(inp) #32x32x64\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    \n",
    "    #Stage 0 / resblock 0\n",
    "    y   = Conv2D(32, (1,1), strides=1, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(32, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(64, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Conv2D(64, (1,1), strides=1, **kwargs) (x)\n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 0 / resblock 1\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    y   = Conv2D(32, (1,1), strides=1, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(32, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(64, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 1 / resblock 0\n",
    "    y   = Conv2D(64, (1,1), strides=2, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(64, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(128, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Conv2D(128, (1,1), strides=2, **kwargs) (x)\n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 1 / resblock 1\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    y   = Conv2D(64, (1,1), strides=1, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(64, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(128, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 2 / resblock 0\n",
    "    y   = Conv2D(128, (1,1), strides=2, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(128, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(256, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Conv2D(256, (1,1), strides=2, **kwargs) (x)\n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 2 / resblock 1\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    y   = Conv2D(128, (1,1), strides=1, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(128, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(256, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 3 / resblock 0\n",
    "    y   = Conv2D(256, (1,1), strides=2, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(256, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(512, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Conv2D(512, (1,1), strides=2, **kwargs) (x)\n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 2 / resblock 1\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    y   = Conv2D(256, (1,1), strides=1, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(256, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(512, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Final\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    x   = AveragePooling2D(pool_size=8)(x)\n",
    "    x   = Flatten()(x)\n",
    "   \n",
    "    #x = Dropout(1/32)(x)\n",
    "    \n",
    "    x = Dense (64, activation ='tanh',kernel_initializer='he_normal') (x)\n",
    "\n",
    "    \n",
    "    ##Create model\n",
    "    model = Model(inputs = inp, outputs = x, name='EmbModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define our global model\n",
    "def global_model(size, channel_size=1, l2=1e-4):\n",
    "    input_size = (size, size, channel_sz)                     \n",
    "\n",
    "    A = Input(input_size)\n",
    "    P = Input(input_size)\n",
    "    N = Input(input_size)\n",
    "\n",
    "    emb_model= EmbModel(input_size, l2)\n",
    "\n",
    "    out_A = emb_model(A)\n",
    "    out_P = emb_model(P)\n",
    "    out_N = emb_model(N)\n",
    "\n",
    "    y_pred = concatenate([out_A, out_P, out_N], axis =-1)\n",
    "\n",
    "    full_model = Model(inputs = [A, P, N], outputs = y_pred)\n",
    "    \n",
    "    return full_model, emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model, b_size = 32, ep = 50):\n",
    "\n",
    "    A,P,N = triplets_list_train\n",
    "    A_test, P_test, N_test = triplets_list_test\n",
    "    zeros_vect = np.zeros(A[:,1,1].shape)\n",
    "    zeros_vect_test = np.zeros(A_test[:,1,1].shape) \n",
    "    class_model.fit(x = [A, P, N] , \n",
    "                             y = zeros_vect , \n",
    "                             batch_size = b_size, \n",
    "                             epochs = ep,\n",
    "                             validation_data = ([A_test, P_test, N_test], zeros_vect_test), \n",
    "                             shuffle = True)\n",
    "    return class_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model, emb_model = global_model(SZ,channel_sz, l2=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EmbModel (Model)                (None, 64)           2401728     input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192)          0           EmbModel[1][0]                   \n",
      "                                                                 EmbModel[2][0]                   \n",
      "                                                                 EmbModel[3][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,401,728\n",
      "Trainable params: 2,394,880\n",
      "Non-trainable params: 6,848\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 64, 64, 32)   320         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 64, 64, 32)   128         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 64, 64, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 32)   1056        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 64, 64, 32)   128         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 64, 64, 32)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 32)   9248        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 64, 64, 32)   128         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 64, 64, 32)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 64, 64, 64)   2112        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 64, 64, 64)   2112        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 64, 64, 64)   0           conv2d_63[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 64, 64, 64)   256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 64, 64, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 64, 64, 32)   2080        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 64, 64, 32)   128         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 64, 64, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 64, 64, 32)   9248        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 64, 64, 32)   128         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 64, 64, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 64, 64, 64)   2112        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 64, 64, 64)   0           activation_48[0][0]              \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 32, 32, 64)   4160        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 32, 32, 64)   256         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 32, 32, 64)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 32, 32, 64)   36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 32, 32, 64)   256         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 32, 32, 64)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 128)  8320        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 128)  8320        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 32, 32, 128)  0           conv2d_70[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 32, 32, 128)  512         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 32, 32, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 64)   8256        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 32, 32, 64)   256         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 32, 32, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 32, 32, 64)   36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 32, 32, 64)   256         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 32, 32, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 32, 32, 128)  8320        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 32, 32, 128)  0           activation_53[0][0]              \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 128)  16512       add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 16, 16, 128)  512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 16, 16, 128)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 16, 128)  147584      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 16, 16, 128)  512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 16, 16, 128)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 256)  33024       add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 256)  33024       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 16, 16, 256)  0           conv2d_77[0][0]                  \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 16, 16, 256)  1024        add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16, 16, 256)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 128)  32896       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 16, 16, 128)  512         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 16, 16, 128)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 16, 16, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 16, 16, 128)  512         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 16, 16, 128)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 256)  33024       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 16, 16, 256)  0           activation_58[0][0]              \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 256)    65792       add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 256)    1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 256)    590080      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 256)    1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 256)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 512)    131584      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 512)    131584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 8, 512)    0           conv2d_84[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 512)    2048        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 512)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 256)    131328      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 256)    1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 256)    590080      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 256)    1024        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 256)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 512)    131584      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 8, 8, 512)    0           activation_63[0][0]              \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 512)    2048        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 512)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 512)    0           activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           32832       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,401,728\n",
      "Trainable params: 2,394,880\n",
      "Non-trainable params: 6,848\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model.summary()\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import random_rotation, random_shift, random_shear, random_zoom\n",
    "\n",
    "def augmentation_pipeline(img_arr):\n",
    "    img_arr = random_rotation(img_arr, 30, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    img_arr = random_shear(img_arr, intensity=0.2, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    img_arr = random_zoom(img_arr, zoom_range=(0.85, 1.15), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    img_arr = random_shift(img_arr, wrg=0.15, hrg=0.15,fill_mode='nearest')\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X,Y, bs=32,hardmode = False):\n",
    "    \"\"\"\n",
    "    Create a mini-batch generator\n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of images\n",
    "    Y -- array of classes corresponding to each image\n",
    "    bs -- size of the minibatch\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    [A_batch, P_batch, N_batch], y_dummie) -- a mini-batch of size bs\n",
    "    \"\"\"\n",
    "    \n",
    "    Y = Y.reshape(Y.shape[0],)\n",
    "    while True:\n",
    "        #0. Initialize Anchor,Postive, Negative\n",
    "        A_batch = []\n",
    "        P_batch = []\n",
    "        N_batch = []\n",
    "        for i in range(bs) :\n",
    "            triplet=0\n",
    "            while triplet>=0 and triplet <10:\n",
    "                #1.Choose a random Anchor Image\n",
    "                rand_A_num = np.random.randint(X.shape[0])\n",
    "                \n",
    "\n",
    "                #2.Choose a random Positive Image\n",
    "                list_pos = X[Y==Y[rand_A_num]]                            #List of positive images\n",
    "                rand_P_num = np.random.randint(len(list_pos))\n",
    "                while np.array_equal(X[rand_A_num],list_pos[rand_P_num]):\n",
    "                    rand_P_num = np.random.randint(len(list_pos))\n",
    "                \n",
    "\n",
    "                #3.Choose a random Negative Image\n",
    "                rand_N_num = np.random.randint(X.shape[0])\n",
    "                while np.array_equal(Y[rand_N_num], Y[rand_A_num]):\n",
    "                    rand_A_num = np.random.randint(X.shape[0])\n",
    "                \n",
    "                loss = -1\n",
    "                if hardmode==True : \n",
    "                    A_augment = augmentation_pipeline(X[rand_A_num])\n",
    "                    P_augment = augmentation_pipeline(list_pos[rand_P_num])\n",
    "                    N_augment = augmentation_pipeline(X[rand_N_num])\n",
    "                    \n",
    "                    triplet_array = np.array([A_augment, P_augment, N_augment])\n",
    "                    triplet_emb = emb_model.predict(triplet_array)\n",
    "                    triplet_emb = np.reshape(triplet_emb, 192)  #3 * 64\n",
    "                    loss = triplet_loss_np(triplet_emb)\n",
    "                \n",
    "                if loss>=0 or hardmode==False:   #0.2 is alpha here\n",
    "                    if hardmode==False:\n",
    "                        A_augment = augmentation_pipeline(X[rand_A_num])\n",
    "                        P_augment = augmentation_pipeline(list_pos[rand_P_num])\n",
    "                        N_augment = augmentation_pipeline(X[rand_N_num])\n",
    "                    \n",
    "                    triplet=-1\n",
    "                    A_batch.append(A_augment)\n",
    "                    P_batch.append(P_augment)\n",
    "                    N_batch.append(N_augment)\n",
    "            \n",
    "        A_batch = np.array(A_batch)\n",
    "        P_batch = np.array(P_batch)\n",
    "        N_batch = np.array(N_batch)\n",
    "        \n",
    "        y_dummie = np.zeros((len(A_batch),))\n",
    "        \n",
    "        yield ([A_batch, P_batch, N_batch], y_dummie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real shit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint and early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TANH32-1.h5\n",
      "Epoch 1/200\n",
      "549/550 [============================>.] - ETA: 0s - loss: 400.6861 - triplet_acc: 0.8185"
     ]
    }
   ],
   "source": [
    "#Full network 1/32 - Embeddings 64 - Maxout\n",
    "A_val, P_val, N_val = triplets_list_val\n",
    "zeros_vect_val = np.zeros(A_val[:,1,1].shape) \n",
    "\n",
    "\n",
    "batch_sz = 8\n",
    "\n",
    "\n",
    "for num in range(1, 10):\n",
    "    model_name = 'TANH32-%01d.h5' % num\n",
    "    print(model_name)\n",
    "    \n",
    "    #We create a checkpoint to save the best model and add an early stopping\n",
    "    checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "    lr_annealing = ReduceLROnPlateau(monitor='val_loss', patience = 3, epsilon=0.01, factor = 0.25, min_lr = 0.000001, verbose = 1, mode='min' )\n",
    "    callbacks_list = [checkpoint, early_stop, lr_annealing]\n",
    "    \n",
    "\n",
    "    #We compile our model with the custom made triplet_loss\n",
    "    classification_model.compile(optimizer = 'adam', loss = triplet_loss, metrics =[triplet_acc])\n",
    "    \n",
    "    classification_model.fit_generator(batch_generator(X_train, Y_train, batch_sz, hardmode=False), \n",
    "                                   steps_per_epoch = 550,\n",
    "                                   epochs = 200,\n",
    "                                   verbose = 1,\n",
    "                                   validation_data = ([A_val, P_val, N_val], zeros_vect_val),\n",
    "                                   callbacks = callbacks_list,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19770/19770 [==============================] - 40s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 42s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tanh-7.h5', 77.35597676492786)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_loss=1000\n",
    "A_val, P_val, N_val = triplets_list_val\n",
    "zeros_vect_val = np.zeros(A_val[:,1,1].shape) \n",
    "\n",
    "for weights in ['tanh-1.h5','tanh-2.h5','tanh-3.h5','tanh-4.h5','tanh-5.h5','tanh-6.h5','tanh-7.h5','tanh-8.h5','tanh-9.h5']:\n",
    "    classification_model.load_weights(weights)\n",
    "    loss, acc = classification_model.evaluate([A_val, P_val, N_val], zeros_vect_val, batch_size=32, verbose=1)\n",
    "    if (loss<global_loss):\n",
    "        model_name = weights\n",
    "        global_loss = loss\n",
    "        \n",
    "classification_model.load_weights(model_name)\n",
    "model_name, global_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.load_weights('tanh-9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105.84354501637546, 0.9885795454545454]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.evaluate_generator(batch_generator(X_test, Y_test, batch_sz),steps=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh-1.h5 182.0325780003721 0.9806818181818182\n",
      "tanh-2.h5 148.22025807120582 0.9832954545454545\n",
      "tanh-3.h5 125.30392979676073 0.9870454545454546\n",
      "tanh-4.h5 141.09272041645917 0.9840340909090909\n",
      "tanh-5.h5 119.49919689752839 0.9871590909090909\n",
      "tanh-6.h5 125.91501070802862 0.98625\n",
      "tanh-7.h5 113.52945247476751 0.9879545454545454\n",
      "tanh-8.h5 106.35614285718312 0.9889772727272728\n",
      "tanh-9.h5 115.49163587429307 0.9869318181818182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tanh-7.h5', 77.35597676492786)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for weights in ['tanh-1.h5','tanh-2.h5','tanh-3.h5','tanh-4.h5','tanh-5.h5','tanh-6.h5','tanh-7.h5','tanh-8.h5','tanh-9.h5']:\n",
    "    classification_model.load_weights(weights)\n",
    "    loss, acc = classification_model.evaluate_generator(batch_generator(X_test, Y_test, batch_sz),steps=550)\n",
    "    print(weights, loss, acc)\n",
    "    if (loss<global_loss):\n",
    "        model_name = weights\n",
    "        global_loss = loss\n",
    "        \n",
    "classification_model.load_weights(model_name)\n",
    "model_name, global_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without dropout batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2, emb2 = global_model(SZ,channel_sz, conv_drop = 0, dense_drop = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2.load_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 60, 60, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 60, 60, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 60, 60, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EmbModel (Model)                (None, 64)           217680      input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 192)          0           EmbModel[1][0]                   \n",
      "                                                                 EmbModel[2][0]                   \n",
      "                                                                 EmbModel[3][0]                   \n",
      "==================================================================================================\n",
      "Total params: 217,680\n",
      "Trainable params: 217,472\n",
      "Non-trainable params: 208\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 60, 60, 1)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 62, 62, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 60, 60, 16)        160       \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 60, 60, 16)        240       \n",
      "_________________________________________________________________\n",
      "a0 (Activation)              (None, 60, 60, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pool0 (Conv2D)           (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 28, 28, 32)        112       \n",
      "_________________________________________________________________\n",
      "a1 (Activation)              (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (Conv2D)           (None, 14, 14, 32)        4128      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 12, 12, 64)        48        \n",
      "_________________________________________________________________\n",
      "a2 (Activation)              (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pool2 (Conv2D)           (None, 6, 6, 64)          16448     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 4, 4, 128)         16        \n",
      "_________________________________________________________________\n",
      "a3 (Activation)              (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pool3 (Conv2D)           (None, 2, 2, 128)         65664     \n",
      "_________________________________________________________________\n",
      "f3 (Flatten)                 (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 217,680\n",
      "Trainable params: 217,472\n",
      "Non-trainable params: 208\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2.summary(), emb2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19770/19770 [==============================] - 41s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[85.74190055845239, 0.9915022761760243]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2.compile(optimizer = 'adam', loss = triplet_loss, metrics =[triplet_acc])\n",
    "class2.evaluate([A_val, P_val, N_val], zeros_vect_val, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "550/550 [==============================] - 153s 278ms/step - loss: 27.9376 - triplet_acc: 0.9970 - val_loss: 85.7419 - val_triplet_acc: 0.9915\n",
      "\n",
      "Epoch 00001: val_loss improved from 88.47650 to 85.74190, saving model to hard.h5\n",
      "Epoch 2/10\n",
      "550/550 [==============================] - 155s 282ms/step - loss: 28.3022 - triplet_acc: 0.9976 - val_loss: 85.7419 - val_triplet_acc: 0.9915\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/10\n",
      "173/550 [========>.....................] - ETA: 1:20 - loss: 30.0327 - triplet_acc: 0.9967"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-6d131a3c8b7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                                    \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                    \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mA_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeros_vect_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                                    \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                                   )\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2210\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2212\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m                     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for layer in class2.layers:\n",
    "    if not isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = False\n",
    "class2.compile(optimizer = 'adam', loss = triplet_loss, metrics =[triplet_acc])\n",
    "class2.fit_generator(batch_generator(X_train, Y_train, batch_sz, hardmode=False), \n",
    "                                   steps_per_epoch = 550,\n",
    "                                   epochs = 10,\n",
    "                                   verbose = 1,\n",
    "                                   validation_data = ([A_val, P_val, N_val], zeros_vect_val),\n",
    "                                   callbacks = callbacks_list\n",
    "                                  )\n",
    "\n",
    "for layer in class2.layers:\n",
    "    if not isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = True\n",
    "class2.compile(optimizer = 'adam', loss = triplet_loss, metrics =[triplet_acc])\n",
    "class2.save('final.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_emb(emb_model, item):\n",
    "    classification_model.load_weights('tanh-7.h5')\n",
    "    emb1 = emb_model.predict_on_batch(item)\n",
    "    \n",
    "    classification_model.load_weights('tanh-8.h5')\n",
    "    emb2 = emb_model.predict_on_batch(item)\n",
    "    \n",
    "    classification_model.load_weights('tanh-9.h5')\n",
    "    emb3 = emb_model.predict_on_batch(item)\n",
    "    \n",
    "    emb = np.mean([emb1,emb2,emb3],axis = 0)\n",
    "    \n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with Modified Hausdorff Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo_classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNDistance(itemA, itemB):\n",
    "    itemA = itemA.reshape(1, itemA.shape[0], itemA.shape[1], 1)\n",
    "    itemB = itemB.reshape(1, itemB.shape[0], itemB.shape[1], 1)\n",
    "    itemA_emb = emb_model.predict_on_batch(itemA)\n",
    "    itemB_emb = emb_model.predict_on_batch(itemB)\n",
    "    dist = np.linalg.norm(itemA_emb - itemB_emb) #2-norm by default\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImgAsArray(fn):\n",
    "\t# Load image file, return as array and resize\n",
    "    picture = mpimg.imread(fn)\n",
    "    image = resize(picture, (SZ,SZ), mode='constant')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-shot classification with Modified Hausdorff Distance versus Siamese triplet loss Distance\n",
      " run 1 ModHausdorffDistance(error 45.0%)  -  Siamese_triplet_loss_Distance (error 20.0%)\n",
      " run 2 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 3 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " run 4 ModHausdorffDistance(error 25.0%)  -  Siamese_triplet_loss_Distance (error 20.0%)\n",
      " run 5 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 6 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 7 ModHausdorffDistance(error 60.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 8 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 9 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 10 ModHausdorffDistance(error 55.0%)  -  Siamese_triplet_loss_Distance (error 25.0%)\n",
      " run 11 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " run 12 ModHausdorffDistance(error 70.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 13 ModHausdorffDistance(error 65.0%)  -  Siamese_triplet_loss_Distance (error 30.0%)\n",
      " run 14 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 15 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 16 ModHausdorffDistance(error 25.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 17 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 20.0%)\n",
      " run 18 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 19 ModHausdorffDistance(error 70.0%)  -  Siamese_triplet_loss_Distance (error 20.0%)\n",
      " run 20 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " average error ModHausdorffDistance 38.75%  average error Siamese_triplet_loss_Distance 12.5%\n"
     ]
    }
   ],
   "source": [
    "print ('One-shot classification with Modified Hausdorff Distance versus Siamese triplet loss Distance')\n",
    "perror = np.zeros(nrun)\n",
    "perror_cnn =np.zeros(nrun)\n",
    "for r in range(1,nrun+1):\n",
    "\trs = str(r)\n",
    "\tif len(rs)==1:\n",
    "\t\trs = '0' + rs\t\t\n",
    "\tperror[r-1] = classification_run('one-shot-classification','/run'+rs, LoadImgAsPoints, ModHausdorffDistance, 'cost')\n",
    "\tperror_cnn[r-1] = classification_run('one-shot-classification','run'+rs, LoadImgAsArray, CNNDistance, 'cost')\n",
    "\tprint (\" run \" + str(r) + \" ModHausdorffDistance\" + \"(error \" + str(\tperror[r-1] ) + \"%)\"+ \"  -  Siamese_triplet_loss_Distance\" + \" (error \" + str(\tperror_cnn[r-1] ) + \"%)\")\t\t\n",
    "total = np.mean(perror)\n",
    "total_cnn = np.mean(perror_cnn)\n",
    "print (\" average error ModHausdorffDistance \" + str(total) + \"%\" + \"  average error Siamese_triplet_loss_Distance \" + str(total_cnn) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNDistance(itemA, itemB):\n",
    "    itemA = itemA.reshape(1, itemA.shape[0], itemA.shape[1], 1)\n",
    "    itemB = itemB.reshape(1, itemB.shape[0], itemB.shape[1], 1)\n",
    "    itemA_emb = final_emb(emb_model, itemA)\n",
    "    itemB_emb = final_emb(emb_model, itemB)\n",
    "    dist = np.linalg.norm(itemA_emb - itemB_emb) #2-norm by default\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-shot classification with Modified Hausdorff Distance versus Siamese triplet loss Distance\n",
      " run 1 ModHausdorffDistance(error 45.0%)  -  Siamese_triplet_loss_Distance (error 25.0%)\n",
      " run 2 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 30.0%)\n",
      " run 3 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " run 4 ModHausdorffDistance(error 25.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 5 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 6 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " run 7 ModHausdorffDistance(error 60.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 8 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 9 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 10 ModHausdorffDistance(error 55.0%)  -  Siamese_triplet_loss_Distance (error 35.0%)\n",
      " run 11 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " run 12 ModHausdorffDistance(error 70.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 13 ModHausdorffDistance(error 65.0%)  -  Siamese_triplet_loss_Distance (error 25.0%)\n",
      " run 14 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 15 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 16 ModHausdorffDistance(error 25.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 17 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 18 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 20.0%)\n",
      " run 19 ModHausdorffDistance(error 70.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 20 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " average error ModHausdorffDistance 38.75%  average error Siamese_triplet_loss_Distance 12.5%\n"
     ]
    }
   ],
   "source": [
    "print ('One-shot classification with Modified Hausdorff Distance versus Siamese triplet loss Distance')\n",
    "perror = np.zeros(nrun)\n",
    "perror_cnn =np.zeros(nrun)\n",
    "for r in range(1,nrun+1):\n",
    "\trs = str(r)\n",
    "\tif len(rs)==1:\n",
    "\t\trs = '0' + rs\t\t\n",
    "\tperror[r-1] = classification_run('one-shot-classification','/run'+rs, LoadImgAsPoints, ModHausdorffDistance, 'cost')\n",
    "\tperror_cnn[r-1] = classification_run('one-shot-classification','run'+rs, LoadImgAsArray, CNNDistance, 'cost')\n",
    "\tprint (\" run \" + str(r) + \" ModHausdorffDistance\" + \"(error \" + str(\tperror[r-1] ) + \"%)\"+ \"  -  Siamese_triplet_loss_Distance\" + \" (error \" + str(\tperror_cnn[r-1] ) + \"%)\")\t\t\n",
    "total = np.mean(perror)\n",
    "total_cnn = np.mean(perror_cnn)\n",
    "print (\" average error ModHausdorffDistance \" + str(total) + \"%\" + \"  average error Siamese_triplet_loss_Distance \" + str(total_cnn) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13180, 60, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "test_array= test_array.reshape(test_array.shape[0],test_array.shape[1],test_array.shape[2],channel_sz)\n",
    "print(test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13180,)\n"
     ]
    }
   ],
   "source": [
    "class_char_test=np.array([])\n",
    "for i in range(13180//20):\n",
    "    #As each character have 20 examples\n",
    "    class_char_test= np.concatenate((class_char_test, np.ones(20)*(i+1))) \n",
    "class_char_test = class_char_test.astype(int)\n",
    "print(class_char_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13180, 1)\n"
     ]
    }
   ],
   "source": [
    "class_char_test=class_char_test.reshape(class_char_test.shape[0],1)\n",
    "print(class_char_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_eval, Y_test, Y_eval = train_test_split(test_array, class_char_test, test_size=0.7, stratify= class_char_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_list_eval = create_triplets(X_eval, Y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119938/119938 [==============================] - 145s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8782454858518958"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_eval, P_eval, N_eval = triplets_list_eval\n",
    "zeros_vect_eval = np.zeros(A_eval[:,1,1].shape) \n",
    "\n",
    "classification_model.evaluate([A_eval, P_eval, N_eval], zeros_vect_eval, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

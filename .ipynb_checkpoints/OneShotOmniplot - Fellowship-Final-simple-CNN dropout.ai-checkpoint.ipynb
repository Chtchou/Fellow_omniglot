{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot learning - Omniglot - Fellowship.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fellowship.ai - Few-shot learning\n",
    "This is my personal project to the few-shot learning challenge from [Fellowship.ai](https://fellowship.ai/challenge/) with the following goal:\n",
    "> Omniglot, the “transpose” of MNIST, with 1623 character classes, each with 20 examples.  Build a few-shot classifier with a target of <35% error.\n",
    "\n",
    "#### Omniglot - Dataset\n",
    "*Dataset reference:* [Link](https://github.com/brendenlake/omniglot)\n",
    "> Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332-1338.\n",
    "\n",
    "The Omniglot dataset is often considered as the transpose of the MNIST dataset. While the latter contains only 10 classes with a training set of 60000 examples, Omniglot contains an important number of classes (1623 different handwritten characters from 50 different alphabets) with only a low number of examples (20) for each, making it an ideal dataset for few-shot learning problems.\n",
    "\n",
    "#### Few-shot learning\n",
    "Whereas, lots of deep learning projects are based on a huge number of training examples to be trained, few-shot learning is  based only on a few one. This approach is much closer to the one experienced by humans. We are able to memorize and recognize objects we have never seen before from a few number of examples. Then for each new encounter with these types of object we can classify them in an accurate and easy way.\n",
    "\n",
    "\n",
    "#### Stategy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, concatenate,AveragePooling2D, MaxPooling2D, Dropout, Lambda, Add\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image                                                                                                                               \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.transform import resize\n",
    "import h5py\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indicate the PATH of the training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training images path\n",
    "PATH=\"images_background/\"\n",
    "\n",
    "#Validation and test images path\n",
    "PATH_TEST = \"images_evaluation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a look at the list of all alphabets contained in the training set, and their total number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of the different alphabets:\n",
      " ['Syriac_(Estrangelo)' 'Armenian' 'Latin' 'Hebrew' 'Tifinagh'\n",
      " 'Burmese_(Myanmar)' 'Japanese_(katakana)' 'Anglo-Saxon_Futhorc'\n",
      " 'Ojibwe_(Canadian_Aboriginal_Syllabics)' 'Asomtavruli_(Georgian)'\n",
      " 'Blackfoot_(Canadian_Aboriginal_Syllabics)' 'Japanese_(hiragana)' 'Greek'\n",
      " 'Futurama' 'Alphabet_of_the_Magi' 'Grantha' 'Bengali' 'N_Ko' 'Balinese'\n",
      " 'Gujarati' 'Early_Aramaic' 'Inuktitut_(Canadian_Aboriginal_Syllabics)'\n",
      " 'Mkhedruli_(Georgian)' 'Sanskrit' 'Korean' 'Braille' 'Tagalog'\n",
      " 'Malay_(Jawi_-_Arabic)' 'Arcadian' 'Cyrillic']\n",
      "\n",
      "Number of different alphabets: 30\n"
     ]
    }
   ],
   "source": [
    "alph_type = np.array(os.listdir(PATH)) #Give the different types of alphabet in our training data\n",
    "print(f\"List of the different alphabets:\\n {alph_type}\")\n",
    "print(f\"\\nNumber of different alphabets: {len(alph_type)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check the number of character for each alphabets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The maximum number of different character for one alphabet is 55\n",
      "The minimum number of different character for one alphabet is 14\n",
      "The total number of different character is 964\n"
     ]
    }
   ],
   "source": [
    "alph_num_char ={alphabet:len(os.listdir(f'{PATH}{alphabet}')) for alphabet in alph_type}\n",
    "num_of_char = alph_num_char.values()\n",
    "\n",
    "plt.bar(range(len(alph_type)),num_of_char)\n",
    "plt.xticks(range(len(alph_type)), [alph[:10] for alph in alph_type], rotation=90)\n",
    "plt.title('Number of characters per alphabet')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nThe maximum number of different character for one alphabet is {max(num_of_char)}')\n",
    "print(f'The minimum number of different character for one alphabet is {min(num_of_char)}')\n",
    "total_char = sum(num_of_char)\n",
    "print(f'The total number of different character is {total_char}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of different pictures is 19280\n"
     ]
    }
   ],
   "source": [
    "alph_num_char_ex={}\n",
    "for alphabet in alph_type:\n",
    "    char_list=os.listdir(f'{PATH}{alphabet}')\n",
    "    for char in char_list:\n",
    "        alph_num_char_ex[(alphabet,char)]= len(os.listdir(f'{PATH}{alphabet}/{char}'))\n",
    "\n",
    "num_of_example = alph_num_char_ex.values()\n",
    "\n",
    "plt.bar(range(len(alph_num_char_ex)),num_of_example)\n",
    "plt.title('Number of example pictures per character')\n",
    "plt.show()\n",
    "\n",
    "total_example = sum(num_of_example) \n",
    "print(f'The total number of different pictures is {total_example}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that each character have 20 examples(pictures) and that our training set is well balanced. For our training we will consider that each character is an independent class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add label for each character\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each picture in our dataset we give a corresponding label(an integer) which allow us to determine the corresponding character. Here an integer is sufficient as we are not really interested in knowing from which alphabet an image is coming from and as we don't have need to know the character name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.array([i//20+1 for i in range(total_example)])\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reshape, our data to have the number of channel including (here is 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train=Y_train.reshape(*Y_train.shape,1)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert images to datafile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first retrieve the path for each picture in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images_background/Syriac_(Estrangelo)/character17/0289_20.png',\n",
       " 'images_background/Syriac_(Estrangelo)/character17/0289_08.png',\n",
       " 'images_background/Syriac_(Estrangelo)/character17/0289_12.png',\n",
       " 'images_background/Syriac_(Estrangelo)/character17/0289_17.png',\n",
       " 'images_background/Syriac_(Estrangelo)/character17/0289_05.png']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train set\n",
    "imagePath = glob.glob(f\"{PATH}*/*/*.png\")\n",
    "\n",
    "#Test set\n",
    "testPath = glob.glob(f\"{PATH_TEST}*/*/*.png\")\n",
    "\n",
    "imagePath[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print some random images of the dataset, convert them to arrays and resize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SZ=64 #Dimension of the output image expected\n",
    "\n",
    "#Dimensions of the grill of sample pictures\n",
    "columns = 4\n",
    "rows = 5\n",
    "\n",
    "fig=plt.figure(figsize=(5, 5))\n",
    "\n",
    "#Print 20 random examples of images\n",
    "list_example = np.random.randint(total_example, size = columns*rows)\n",
    "pos=0\n",
    "for i in list_example:\n",
    "    pos+=1\n",
    "    img = mpimg.imread(imagePath[i])\n",
    "    img = resize(img, (SZ,SZ), mode='reflect')\n",
    "    fig.add_subplot(rows, columns, pos)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images seems clear and well centered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert all images into arrays and resize them to the 60x60 format. We concatenate all arrays into the variable im_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280, 64, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train set\n",
    "#Transform in array and resize all 19280 images \n",
    "X_train = np.array([resize(mpimg.imread(i), (SZ,SZ), mode='reflect') for i in imagePath] )\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reshape the image to take into account the number of channel to pass them in our CNN, which is 1 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280, 64, 64, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_sz = 1 #number of channel\n",
    "X_train= X_train.reshape(*X_train.shape, channel_sz)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13180, 64, 64, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test set\n",
    "test_array = np.array([resize(mpimg.imread(i), (SZ,SZ), mode='reflect') for i in testPath] )\n",
    "test_array= test_array.reshape(*test_array.shape, channel_sz)\n",
    "test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13180, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_char_test = np.array([i//20+1 for i in range(test_array.shape[0])])\n",
    "class_char_test = class_char_test.reshape(*class_char_test.shape,1)\n",
    "class_char_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/ validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the traning set into Train and Validation sets of pictures (Train : 70%, Validation : 30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_valid, Y_train, Y_valid = train_test_split(im_array, class_char, test_size=0.3, stratify= class_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train.shape, X_valid.shape, Y_train.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3954, 64, 64, 1), (9226, 64, 64, 1), (3954, 1), (9226, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(test_array, class_char_test, test_size=0.7, stratify= class_char_test)\n",
    "X_val.shape, X_test.shape, Y_val.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our loss function is determined by the following triplet loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 64)\n",
    "            positive -- the encodings for the positive images, of shape (None, 64)\n",
    "            negative -- the encodings for the negative images, of shape (None, 64)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[:,0:64], y_pred[:,64:128], y_pred[:,128:196]\n",
    "    \n",
    "    #Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = -1))\n",
    "    #Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = -1))\n",
    "    #Subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\n",
    "    valid_triplets = tf.to_float(tf.greater(basic_loss,0))\n",
    "    num_positive_triplets = tf.reduce_sum(valid_triplets)\n",
    "    #Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0))/ alpha * 100 #/ (num_positive_triplets + 1e-16)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss_np(y_pred, alpha = 0.2):\n",
    "    anchor, positive, negative = y_pred[0:64], y_pred[64:128], y_pred[128:196]\n",
    "    positive_distance = np.square(anchor - positive)\n",
    "    negative_distance = np.square(anchor - negative)\n",
    "   \n",
    "    positive_distance = np.sqrt(np.sum(positive_distance, axis=-1, keepdims=True))\n",
    "    negative_distance = np.sqrt(np.sum(negative_distance, axis=-1, keepdims=True))\n",
    "   \n",
    "    basic_loss = alpha + (positive_distance - negative_distance)\n",
    "    return basic_loss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_acc(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 64)\n",
    "            positive -- the encodings for the positive images, of shape (None, 64)\n",
    "            negative -- the encodings for the negative images, of shape (None, 64)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[:,0:64], y_pred[:,64:128], y_pred[:,128:196]\n",
    "    \n",
    "    #Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = -1)\n",
    "    #Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = -1)\n",
    "    #Subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\n",
    "    hard_triplets = tf.to_float(tf.greater(basic_loss,alpha))\n",
    "    num_hard_triplets = tf.reduce_sum(hard_triplets)\n",
    "    #Count number of triplets\n",
    "    all_triplets = tf.reduce_sum(tf.to_float(tf.greater(basic_loss,-10**10)))\n",
    "    \n",
    "    #Accuracy\n",
    "    acc = 1 - num_hard_triplets/all_triplets\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Triplet Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triplets(X, Y, num=1):\n",
    "    \"\"\"\n",
    "    Create a list of valid triplets\n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of images\n",
    "    Y -- array of classes corresponding to each image\n",
    "    num -- number of negative images for each valid anchor and positive images - must be positive\n",
    "           if num = 0, all possible valid couples are created\n",
    "            For example : for one valid (A,P) couple we can select 'num' random N images. \n",
    "                          Thus 'num' triplets are created for this (A,P) couple\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    (A,P,N) -- python tuple containing 3 arrays : \n",
    "            A -- the array for the anchor images, of shape (None, 64)\n",
    "            P -- the array for the positive images, of shape (None, 64)\n",
    "            N -- the array for the negative images, of shape (None, 64)\n",
    "    \"\"\"\n",
    "\n",
    "    Y = Y.reshape(Y.shape[0],)\n",
    "    A = []\n",
    "    P = []\n",
    "    N = []\n",
    "    \n",
    "    #We loop over all possible valid (A,P)\n",
    "    for i in range(X.shape[0]):  \n",
    "        list_pos = X[Y==Y[i]]\n",
    "        for j in list_pos:\n",
    "            #We provide a number 'num' of triplets for each valid (A,P)\n",
    "            if num >=1:\n",
    "                for k in range(num):\n",
    "                    rand_num = np.random.randint(X.shape[0])\n",
    "                    if np.array_equal(X[i],j) == False:\n",
    "                        A.append(X[i])\n",
    "                        P.append(j)\n",
    "                        while np.array_equal(Y[rand_num], Y[i]):\n",
    "                            rand_num = np.random.randint(X.shape[0])\n",
    "                        N.append(X[rand_num])\n",
    "            if num == 0:\n",
    "                for k in range(X.shape[0]):\n",
    "                    if np.array_equal(X[i],j) == False:\n",
    "                        if np.array_equal(Y[i],Y[k]) == False:\n",
    "                            A.append(X[i])\n",
    "                            P.append(j)\n",
    "                            N.append(X[k])\n",
    "    \n",
    "    A = np.array(A)\n",
    "    P = np.array(P)\n",
    "    N = np.array(N)\n",
    "    \n",
    "    return (A, P, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'triplets_list_valid = create_triplets(X_valid,Y_valid)\\nfor i in range(len(triplets_list_valid)):\\n    print(triplets_list_valid[i].shape)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We create one triplet for each of the possible (A,P) couple in our validation set \n",
    "\"\"\"triplets_list_valid = create_triplets(X_valid,Y_valid)\n",
    "for i in range(len(triplets_list_valid)):\n",
    "    print(triplets_list_valid[i].shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(19770, 64, 64, 1), (19770, 64, 64, 1), (19770, 64, 64, 1)]\n"
     ]
    }
   ],
   "source": [
    "triplets_list_val = create_triplets(X_val, Y_val)\n",
    "print([i.shape for i in triplets_list_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a number of 28920 examples for the validation. Thus 1 negative image per (A,P) couple is enough for our evaluation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmbModel(input_shape, conv_drop=0, dense_drop=1/32):\n",
    "    \"\"\"\n",
    "    Define our shared embedding model\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of array of input images\n",
    "    conv_drop -- dropout rate for CNN layers\n",
    "    dense_drop -- dropout rate for Dense layer\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    model - Our model which transform an array of images into an array of embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Define the input placeholder as a tensor with shape input_shape.\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #CONV\n",
    "    X = Conv2D(64,(3,3),strides =(1,1), name ='conv0', padding='same', kernel_initializer='glorot_uniform') (X_input)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn0\") (X)\n",
    "    X = Activation('relu', name='a0')(X)\n",
    "    X = Conv2D(64,(3,3),strides =(1,1), name ='conv0b',padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn0b\") (X)\n",
    "    X = Activation('relu', name='a0b')(X)\n",
    "    \n",
    "    #MAXPOOL\n",
    "    X = MaxPooling2D((2,2), name='max_pool0')(X)\n",
    "    #X = Conv2D(16,(2,2), strides=(2,2), name='max_pool0')(X)\n",
    "    \n",
    "    X = Dropout(conv_drop)(X)\n",
    "    \n",
    "    \n",
    "     #CONV\n",
    "    Y = X\n",
    "    X = Conv2D(128,(3,3),strides =(1,1), name ='conv1', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn1\") (X)\n",
    "    X = Activation('relu', name='a1')(X)\n",
    "    X = Conv2D(128,(3,3),strides =(1,1), name ='convb1', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn1b\") (X)\n",
    "    X = Activation('relu', name='a1b')(X)\n",
    "    \n",
    "    \n",
    "    #MAXPOOL\n",
    "    X = MaxPooling2D((2,2), name='max_pool1')(X)\n",
    "    #X = Conv2D(32,(2,2), strides=(2,2), name='max_pool1')(X)\n",
    "    \n",
    "    X = Dropout(conv_drop)(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "     #CONV\n",
    "    X = Conv2D(128,(3,3),strides =(1,1), name ='conv2', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn2\") (X)\n",
    "    X = Activation('relu', name='a2')(X)\n",
    "    X = Conv2D(128,(3,3),strides =(1,1), name ='conv2b', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn2b\") (X)\n",
    "    X = Activation('relu', name='a2b')(X)\n",
    "    \n",
    "     #MAXPOOL\n",
    "    X = MaxPooling2D((2,2), name='max_pool2')(X)\n",
    "    #X = Conv2D(64,(2,2), strides=(2,2), name='max_pool2')(X)\n",
    "    \n",
    "    X = Dropout(conv_drop)(X)\n",
    "    \n",
    "    #Padding\n",
    "    #X = ZeroPadding2D((1,1))(X)\n",
    "    \n",
    "     #CONV\n",
    "    X = Conv2D(256,(3,3),strides =(1,1), name ='conv3', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn3\") (X)\n",
    "    X = Activation('relu', name='a3')(X)\n",
    "    X = Conv2D(256,(3,3),strides =(1,1), name ='conv3b', padding='same', kernel_initializer='glorot_uniform') (X)\n",
    "    X = BatchNormalization(axis = 1, name = \"bn3b\") (X)\n",
    "    X = Activation('relu', name='a3b')(X)\n",
    "    \n",
    "     #MAXPOOL\n",
    "    X = MaxPooling2D((2,2), name='max_pool3')(X)\n",
    "    #X = Conv2D(128,(2,2), strides=(2,2), name='max_pool3')(X)\n",
    "    \n",
    "    #X = Dropout(0.2)(X)\n",
    "    \n",
    "    #FLATTEN X + FC\n",
    "    X = Flatten(name='f3')(X)\n",
    "    #X = Dense (256, activation ='relu', name='fc4', kernel_initializer='glorot_uniform') (X)\n",
    "    X = Dropout(dense_drop)(X)\n",
    "    X = Dense (64, activation ='tanh', name='fc5', kernel_initializer='glorot_uniform') (X)\n",
    "    #X = Lambda(lambda  x: tf.nn.l2_normalize(x,axis=1))(X)\n",
    "    \n",
    "    ##Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='EmbModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "    \n",
    "def EmbModel(input_shape, l2):\n",
    "    ##############\n",
    "    # BRANCH MODEL\n",
    "    ##############\n",
    "    regul  = regularizers.l2(l2)\n",
    "    kwargs = {'padding':'same', 'kernel_regularizer':regul,'kernel_initializer':'he_normal'}\n",
    "\n",
    "    inp = Input(input_shape) # 64x64x1\n",
    "    x   = Conv2D(32, (3,3), strides=1, **kwargs)(inp) #32x32x64\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    \n",
    "    #Stage 0 / resblock 0\n",
    "    y   = Conv2D(32, (1,1), strides=1, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(32, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(64, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Conv2D(64, (1,1), strides=1, **kwargs) (x)\n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 0 / resblock 1\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    y   = Conv2D(32, (1,1), strides=1, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(32, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(64, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 1 / resblock 0\n",
    "    y   = Conv2D(64, (1,1), strides=2, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(64, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(128, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Conv2D(128, (1,1), strides=2, **kwargs) (x)\n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 1 / resblock 1\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    y   = Conv2D(64, (1,1), strides=1, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(64, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(128, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 2 / resblock 0\n",
    "    y   = Conv2D(128, (1,1), strides=2, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(128, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(256, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Conv2D(256, (1,1), strides=2, **kwargs) (x)\n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 2 / resblock 1\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    y   = Conv2D(128, (1,1), strides=1, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(128, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(256, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 3 / resblock 0\n",
    "    y   = Conv2D(256, (1,1), strides=2, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(256, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(512, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Conv2D(512, (1,1), strides=2, **kwargs) (x)\n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Stage 2 / resblock 1\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    y   = Conv2D(256, (1,1), strides=1, **kwargs)(x)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(256, (3,3), strides=1, **kwargs)(y)\n",
    "    \n",
    "    y   = BatchNormalization()(y)\n",
    "    y   = Activation('relu')(y)\n",
    "    y   = Conv2D(512, (1,1), strides=1, **kwargs)(y)\n",
    "    \n",
    "    x   = Add()([x,y])\n",
    "    \n",
    "    #Final\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Activation('relu')(x)\n",
    "    x   = AveragePooling2D(pool_size=8)(x)\n",
    "    x   = Flatten()(x)\n",
    "   \n",
    "    #x = Dropout(1/32)(x)\n",
    "    \n",
    "    x = Dense (64, activation ='tanh',kernel_initializer='he_normal') (x)\n",
    "\n",
    "    \n",
    "    ##Create model\n",
    "    model = Model(inputs = inp, outputs = x, name='EmbModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define our global model\n",
    "def global_model(size, channel_size=1, l2=1e-4):\n",
    "    input_size = (size, size, channel_sz)                     \n",
    "\n",
    "    A = Input(input_size)\n",
    "    P = Input(input_size)\n",
    "    N = Input(input_size)\n",
    "\n",
    "    emb_model= EmbModel(input_size, l2)\n",
    "\n",
    "    out_A = emb_model(A)\n",
    "    out_P = emb_model(P)\n",
    "    out_N = emb_model(N)\n",
    "\n",
    "    y_pred = concatenate([out_A, out_P, out_N], axis =-1)\n",
    "\n",
    "    full_model = Model(inputs = [A, P, N], outputs = y_pred)\n",
    "    \n",
    "    return full_model, emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model, b_size = 32, ep = 50):\n",
    "\n",
    "    A,P,N = triplets_list_train\n",
    "    A_test, P_test, N_test = triplets_list_test\n",
    "    zeros_vect = np.zeros(A[:,1,1].shape)\n",
    "    zeros_vect_test = np.zeros(A_test[:,1,1].shape) \n",
    "    class_model.fit(x = [A, P, N] , \n",
    "                             y = zeros_vect , \n",
    "                             batch_size = b_size, \n",
    "                             epochs = ep,\n",
    "                             validation_data = ([A_test, P_test, N_test], zeros_vect_test), \n",
    "                             shuffle = True)\n",
    "    return class_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model, emb_model = global_model(SZ,channel_sz, l2=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EmbModel (Model)                (None, 64)           2401728     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192)          0           EmbModel[1][0]                   \n",
      "                                                                 EmbModel[2][0]                   \n",
      "                                                                 EmbModel[3][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,401,728\n",
      "Trainable params: 2,394,880\n",
      "Non-trainable params: 6,848\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 32)   320         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 32)   1056        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   2112        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   2112        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 32)   2080        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 32)   9248        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 64)   2112        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           activation_4[0][0]               \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 64)   4160        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 128)  8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 128)  8320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 64)   8256        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 64)   36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 128)  8320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 128)  0           activation_9[0][0]               \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 128)  16512       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 128)  147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 256)  33024       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 256)  33024       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           conv2d_19[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 256)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 128)  32896       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 128)  147584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 256)  33024       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 256)  0           activation_14[0][0]              \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 256)    65792       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 256)    1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 256)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 256)    590080      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 256)    1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 256)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 512)    131584      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 512)    131584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 512)    0           conv2d_26[0][0]                  \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 512)    2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 512)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 256)    131328      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 256)    1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 256)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 256)    590080      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 256)    1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 256)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 512)    131584      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 512)    0           activation_19[0][0]              \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 512)    2048        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 512)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           32832       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,401,728\n",
      "Trainable params: 2,394,880\n",
      "Non-trainable params: 6,848\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model.summary()\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import random_rotation, random_shift, random_shear, random_zoom\n",
    "\n",
    "def augmentation_pipeline(img_arr):\n",
    "    img_arr = random_rotation(img_arr, 30, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    img_arr = random_shear(img_arr, intensity=0.2, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    img_arr = random_zoom(img_arr, zoom_range=(0.85, 1.15), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    img_arr = random_shift(img_arr, wrg=0.15, hrg=0.15,fill_mode='nearest')\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X,Y, bs=32,hardmode = False):\n",
    "    \"\"\"\n",
    "    Create a mini-batch generator\n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of images\n",
    "    Y -- array of classes corresponding to each image\n",
    "    bs -- size of the minibatch\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    [A_batch, P_batch, N_batch], y_dummie) -- a mini-batch of size bs\n",
    "    \"\"\"\n",
    "    \n",
    "    Y = Y.reshape(Y.shape[0],)\n",
    "    while True:\n",
    "        #0. Initialize Anchor,Postive, Negative\n",
    "        A_batch = []\n",
    "        P_batch = []\n",
    "        N_batch = []\n",
    "        for i in range(bs) :\n",
    "            triplet=0\n",
    "            while triplet>=0 and triplet <10:\n",
    "                #1.Choose a random Anchor Image\n",
    "                rand_A_num = np.random.randint(X.shape[0])\n",
    "                \n",
    "\n",
    "                #2.Choose a random Positive Image\n",
    "                list_pos = X[Y==Y[rand_A_num]]                            #List of positive images\n",
    "                rand_P_num = np.random.randint(len(list_pos))\n",
    "                while np.array_equal(X[rand_A_num],list_pos[rand_P_num]):\n",
    "                    rand_P_num = np.random.randint(len(list_pos))\n",
    "                \n",
    "\n",
    "                #3.Choose a random Negative Image\n",
    "                rand_N_num = np.random.randint(X.shape[0])\n",
    "                while np.array_equal(Y[rand_N_num], Y[rand_A_num]):\n",
    "                    rand_A_num = np.random.randint(X.shape[0])\n",
    "                \n",
    "                loss = -1\n",
    "                if hardmode==True : \n",
    "                    A_augment = augmentation_pipeline(X[rand_A_num])\n",
    "                    P_augment = augmentation_pipeline(list_pos[rand_P_num])\n",
    "                    N_augment = augmentation_pipeline(X[rand_N_num])\n",
    "                    \n",
    "                    triplet_array = np.array([A_augment, P_augment, N_augment])\n",
    "                    triplet_emb = emb_model.predict(triplet_array)\n",
    "                    triplet_emb = np.reshape(triplet_emb, 192)  #3 * 64\n",
    "                    loss = triplet_loss_np(triplet_emb)\n",
    "                \n",
    "                if loss>=0 or hardmode==False:   #0.2 is alpha here\n",
    "                    if hardmode==False:\n",
    "                        A_augment = augmentation_pipeline(X[rand_A_num])\n",
    "                        P_augment = augmentation_pipeline(list_pos[rand_P_num])\n",
    "                        N_augment = augmentation_pipeline(X[rand_N_num])\n",
    "                    \n",
    "                    triplet=-1\n",
    "                    A_batch.append(A_augment)\n",
    "                    P_batch.append(P_augment)\n",
    "                    N_batch.append(N_augment)\n",
    "            \n",
    "        A_batch = np.array(A_batch)\n",
    "        P_batch = np.array(P_batch)\n",
    "        N_batch = np.array(N_batch)\n",
    "        \n",
    "        y_dummie = np.zeros((len(A_batch),))\n",
    "        \n",
    "        yield ([A_batch, P_batch, N_batch], y_dummie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real shit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint and early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TANH32-1.h5\n",
      "Epoch 1/200\n",
      "549/550 [============================>.] - ETA: 0s - loss: 400.6861 - triplet_acc: 0.8185"
     ]
    }
   ],
   "source": [
    "#Full network 1/32 - Embeddings 64 - Maxout\n",
    "A_val, P_val, N_val = triplets_list_val\n",
    "zeros_vect_val = np.zeros(A_val[:,1,1].shape) \n",
    "\n",
    "\n",
    "batch_sz = 8\n",
    "\n",
    "\n",
    "for num in range(1, 10):\n",
    "    model_name = 'TANH32-%01d.h5' % num\n",
    "    print(model_name)\n",
    "    \n",
    "    #We create a checkpoint to save the best model and add an early stopping\n",
    "    checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "    lr_annealing = ReduceLROnPlateau(monitor='val_loss', patience = 3, epsilon=0.01, factor = 0.25, min_lr = 0.000001, verbose = 1, mode='min' )\n",
    "    callbacks_list = [checkpoint, early_stop, lr_annealing]\n",
    "    \n",
    "\n",
    "    #We compile our model with the custom made triplet_loss\n",
    "    classification_model.compile(optimizer = 'adam', loss = triplet_loss, metrics =[triplet_acc])\n",
    "    \n",
    "    classification_model.fit_generator(batch_generator(X_train, Y_train, batch_sz, hardmode=False), \n",
    "                                   steps_per_epoch = 550,\n",
    "                                   epochs = 200,\n",
    "                                   verbose = 1,\n",
    "                                   validation_data = ([A_val, P_val, N_val], zeros_vect_val),\n",
    "                                   callbacks = callbacks_list,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19770/19770 [==============================] - 40s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 42s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n",
      "19770/19770 [==============================] - 41s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tanh-7.h5', 77.35597676492786)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_loss=1000\n",
    "A_val, P_val, N_val = triplets_list_val\n",
    "zeros_vect_val = np.zeros(A_val[:,1,1].shape) \n",
    "\n",
    "for weights in ['tanh-1.h5','tanh-2.h5','tanh-3.h5','tanh-4.h5','tanh-5.h5','tanh-6.h5','tanh-7.h5','tanh-8.h5','tanh-9.h5']:\n",
    "    classification_model.load_weights(weights)\n",
    "    loss, acc = classification_model.evaluate([A_val, P_val, N_val], zeros_vect_val, batch_size=32, verbose=1)\n",
    "    if (loss<global_loss):\n",
    "        model_name = weights\n",
    "        global_loss = loss\n",
    "        \n",
    "classification_model.load_weights(model_name)\n",
    "model_name, global_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.load_weights('tanh-9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105.84354501637546, 0.9885795454545454]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.evaluate_generator(batch_generator(X_test, Y_test, batch_sz),steps=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh-1.h5 182.0325780003721 0.9806818181818182\n",
      "tanh-2.h5 148.22025807120582 0.9832954545454545\n",
      "tanh-3.h5 125.30392979676073 0.9870454545454546\n",
      "tanh-4.h5 141.09272041645917 0.9840340909090909\n",
      "tanh-5.h5 119.49919689752839 0.9871590909090909\n",
      "tanh-6.h5 125.91501070802862 0.98625\n",
      "tanh-7.h5 113.52945247476751 0.9879545454545454\n",
      "tanh-8.h5 106.35614285718312 0.9889772727272728\n",
      "tanh-9.h5 115.49163587429307 0.9869318181818182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tanh-7.h5', 77.35597676492786)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for weights in ['tanh-1.h5','tanh-2.h5','tanh-3.h5','tanh-4.h5','tanh-5.h5','tanh-6.h5','tanh-7.h5','tanh-8.h5','tanh-9.h5']:\n",
    "    classification_model.load_weights(weights)\n",
    "    loss, acc = classification_model.evaluate_generator(batch_generator(X_test, Y_test, batch_sz),steps=550)\n",
    "    print(weights, loss, acc)\n",
    "    if (loss<global_loss):\n",
    "        model_name = weights\n",
    "        global_loss = loss\n",
    "        \n",
    "classification_model.load_weights(model_name)\n",
    "model_name, global_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without dropout batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2, emb2 = global_model(SZ,channel_sz, conv_drop = 0, dense_drop = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2.load_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 60, 60, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 60, 60, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 60, 60, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EmbModel (Model)                (None, 64)           217680      input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 192)          0           EmbModel[1][0]                   \n",
      "                                                                 EmbModel[2][0]                   \n",
      "                                                                 EmbModel[3][0]                   \n",
      "==================================================================================================\n",
      "Total params: 217,680\n",
      "Trainable params: 217,472\n",
      "Non-trainable params: 208\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 60, 60, 1)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 62, 62, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 60, 60, 16)        160       \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 60, 60, 16)        240       \n",
      "_________________________________________________________________\n",
      "a0 (Activation)              (None, 60, 60, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pool0 (Conv2D)           (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 28, 28, 32)        112       \n",
      "_________________________________________________________________\n",
      "a1 (Activation)              (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (Conv2D)           (None, 14, 14, 32)        4128      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 12, 12, 64)        48        \n",
      "_________________________________________________________________\n",
      "a2 (Activation)              (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pool2 (Conv2D)           (None, 6, 6, 64)          16448     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 4, 4, 128)         16        \n",
      "_________________________________________________________________\n",
      "a3 (Activation)              (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pool3 (Conv2D)           (None, 2, 2, 128)         65664     \n",
      "_________________________________________________________________\n",
      "f3 (Flatten)                 (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 217,680\n",
      "Trainable params: 217,472\n",
      "Non-trainable params: 208\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2.summary(), emb2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19770/19770 [==============================] - 41s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[85.74190055845239, 0.9915022761760243]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2.compile(optimizer = 'adam', loss = triplet_loss, metrics =[triplet_acc])\n",
    "class2.evaluate([A_val, P_val, N_val], zeros_vect_val, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "550/550 [==============================] - 153s 278ms/step - loss: 27.9376 - triplet_acc: 0.9970 - val_loss: 85.7419 - val_triplet_acc: 0.9915\n",
      "\n",
      "Epoch 00001: val_loss improved from 88.47650 to 85.74190, saving model to hard.h5\n",
      "Epoch 2/10\n",
      "550/550 [==============================] - 155s 282ms/step - loss: 28.3022 - triplet_acc: 0.9976 - val_loss: 85.7419 - val_triplet_acc: 0.9915\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/10\n",
      "173/550 [========>.....................] - ETA: 1:20 - loss: 30.0327 - triplet_acc: 0.9967"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-6d131a3c8b7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                                    \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                    \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mA_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeros_vect_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                                    \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                                   )\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2210\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2212\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m                     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for layer in class2.layers:\n",
    "    if not isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = False\n",
    "class2.compile(optimizer = 'adam', loss = triplet_loss, metrics =[triplet_acc])\n",
    "class2.fit_generator(batch_generator(X_train, Y_train, batch_sz, hardmode=False), \n",
    "                                   steps_per_epoch = 550,\n",
    "                                   epochs = 10,\n",
    "                                   verbose = 1,\n",
    "                                   validation_data = ([A_val, P_val, N_val], zeros_vect_val),\n",
    "                                   callbacks = callbacks_list\n",
    "                                  )\n",
    "\n",
    "for layer in class2.layers:\n",
    "    if not isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = True\n",
    "class2.compile(optimizer = 'adam', loss = triplet_loss, metrics =[triplet_acc])\n",
    "class2.save('final.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_emb(emb_model, item):\n",
    "    classification_model.load_weights('tanh-7.h5')\n",
    "    emb1 = emb_model.predict_on_batch(item)\n",
    "    \n",
    "    classification_model.load_weights('tanh-8.h5')\n",
    "    emb2 = emb_model.predict_on_batch(item)\n",
    "    \n",
    "    classification_model.load_weights('tanh-9.h5')\n",
    "    emb3 = emb_model.predict_on_batch(item)\n",
    "    \n",
    "    emb = np.mean([emb1,emb2,emb3],axis = 0)\n",
    "    \n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with Modified Hausdorff Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo_classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNDistance(itemA, itemB):\n",
    "    itemA = itemA.reshape(1, itemA.shape[0], itemA.shape[1], 1)\n",
    "    itemB = itemB.reshape(1, itemB.shape[0], itemB.shape[1], 1)\n",
    "    itemA_emb = emb_model.predict_on_batch(itemA)\n",
    "    itemB_emb = emb_model.predict_on_batch(itemB)\n",
    "    dist = np.linalg.norm(itemA_emb - itemB_emb) #2-norm by default\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImgAsArray(fn):\n",
    "\t# Load image file, return as array and resize\n",
    "    picture = mpimg.imread(fn)\n",
    "    image = resize(picture, (SZ,SZ), mode='constant')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-shot classification with Modified Hausdorff Distance versus Siamese triplet loss Distance\n",
      " run 1 ModHausdorffDistance(error 45.0%)  -  Siamese_triplet_loss_Distance (error 20.0%)\n",
      " run 2 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 3 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " run 4 ModHausdorffDistance(error 25.0%)  -  Siamese_triplet_loss_Distance (error 20.0%)\n",
      " run 5 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 6 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 7 ModHausdorffDistance(error 60.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 8 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 9 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 10 ModHausdorffDistance(error 55.0%)  -  Siamese_triplet_loss_Distance (error 25.0%)\n",
      " run 11 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " run 12 ModHausdorffDistance(error 70.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 13 ModHausdorffDistance(error 65.0%)  -  Siamese_triplet_loss_Distance (error 30.0%)\n",
      " run 14 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 15 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 16 ModHausdorffDistance(error 25.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 17 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 20.0%)\n",
      " run 18 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 19 ModHausdorffDistance(error 70.0%)  -  Siamese_triplet_loss_Distance (error 20.0%)\n",
      " run 20 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " average error ModHausdorffDistance 38.75%  average error Siamese_triplet_loss_Distance 12.5%\n"
     ]
    }
   ],
   "source": [
    "print ('One-shot classification with Modified Hausdorff Distance versus Siamese triplet loss Distance')\n",
    "perror = np.zeros(nrun)\n",
    "perror_cnn =np.zeros(nrun)\n",
    "for r in range(1,nrun+1):\n",
    "\trs = str(r)\n",
    "\tif len(rs)==1:\n",
    "\t\trs = '0' + rs\t\t\n",
    "\tperror[r-1] = classification_run('one-shot-classification','/run'+rs, LoadImgAsPoints, ModHausdorffDistance, 'cost')\n",
    "\tperror_cnn[r-1] = classification_run('one-shot-classification','run'+rs, LoadImgAsArray, CNNDistance, 'cost')\n",
    "\tprint (\" run \" + str(r) + \" ModHausdorffDistance\" + \"(error \" + str(\tperror[r-1] ) + \"%)\"+ \"  -  Siamese_triplet_loss_Distance\" + \" (error \" + str(\tperror_cnn[r-1] ) + \"%)\")\t\t\n",
    "total = np.mean(perror)\n",
    "total_cnn = np.mean(perror_cnn)\n",
    "print (\" average error ModHausdorffDistance \" + str(total) + \"%\" + \"  average error Siamese_triplet_loss_Distance \" + str(total_cnn) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNDistance(itemA, itemB):\n",
    "    itemA = itemA.reshape(1, itemA.shape[0], itemA.shape[1], 1)\n",
    "    itemB = itemB.reshape(1, itemB.shape[0], itemB.shape[1], 1)\n",
    "    itemA_emb = final_emb(emb_model, itemA)\n",
    "    itemB_emb = final_emb(emb_model, itemB)\n",
    "    dist = np.linalg.norm(itemA_emb - itemB_emb) #2-norm by default\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-shot classification with Modified Hausdorff Distance versus Siamese triplet loss Distance\n",
      " run 1 ModHausdorffDistance(error 45.0%)  -  Siamese_triplet_loss_Distance (error 25.0%)\n",
      " run 2 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 30.0%)\n",
      " run 3 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " run 4 ModHausdorffDistance(error 25.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 5 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 6 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " run 7 ModHausdorffDistance(error 60.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 8 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 9 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 10 ModHausdorffDistance(error 55.0%)  -  Siamese_triplet_loss_Distance (error 35.0%)\n",
      " run 11 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 5.0%)\n",
      " run 12 ModHausdorffDistance(error 70.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 13 ModHausdorffDistance(error 65.0%)  -  Siamese_triplet_loss_Distance (error 25.0%)\n",
      " run 14 ModHausdorffDistance(error 35.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 15 ModHausdorffDistance(error 15.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 16 ModHausdorffDistance(error 25.0%)  -  Siamese_triplet_loss_Distance (error 0.0%)\n",
      " run 17 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 15.0%)\n",
      " run 18 ModHausdorffDistance(error 40.0%)  -  Siamese_triplet_loss_Distance (error 20.0%)\n",
      " run 19 ModHausdorffDistance(error 70.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " run 20 ModHausdorffDistance(error 30.0%)  -  Siamese_triplet_loss_Distance (error 10.0%)\n",
      " average error ModHausdorffDistance 38.75%  average error Siamese_triplet_loss_Distance 12.5%\n"
     ]
    }
   ],
   "source": [
    "print ('One-shot classification with Modified Hausdorff Distance versus Siamese triplet loss Distance')\n",
    "perror = np.zeros(nrun)\n",
    "perror_cnn =np.zeros(nrun)\n",
    "for r in range(1,nrun+1):\n",
    "\trs = str(r)\n",
    "\tif len(rs)==1:\n",
    "\t\trs = '0' + rs\t\t\n",
    "\tperror[r-1] = classification_run('one-shot-classification','/run'+rs, LoadImgAsPoints, ModHausdorffDistance, 'cost')\n",
    "\tperror_cnn[r-1] = classification_run('one-shot-classification','run'+rs, LoadImgAsArray, CNNDistance, 'cost')\n",
    "\tprint (\" run \" + str(r) + \" ModHausdorffDistance\" + \"(error \" + str(\tperror[r-1] ) + \"%)\"+ \"  -  Siamese_triplet_loss_Distance\" + \" (error \" + str(\tperror_cnn[r-1] ) + \"%)\")\t\t\n",
    "total = np.mean(perror)\n",
    "total_cnn = np.mean(perror_cnn)\n",
    "print (\" average error ModHausdorffDistance \" + str(total) + \"%\" + \"  average error Siamese_triplet_loss_Distance \" + str(total_cnn) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13180, 60, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "test_array= test_array.reshape(test_array.shape[0],test_array.shape[1],test_array.shape[2],channel_sz)\n",
    "print(test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13180,)\n"
     ]
    }
   ],
   "source": [
    "class_char_test=np.array([])\n",
    "for i in range(13180//20):\n",
    "    #As each character have 20 examples\n",
    "    class_char_test= np.concatenate((class_char_test, np.ones(20)*(i+1))) \n",
    "class_char_test = class_char_test.astype(int)\n",
    "print(class_char_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13180, 1)\n"
     ]
    }
   ],
   "source": [
    "class_char_test=class_char_test.reshape(class_char_test.shape[0],1)\n",
    "print(class_char_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_eval, Y_test, Y_eval = train_test_split(test_array, class_char_test, test_size=0.7, stratify= class_char_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_list_eval = create_triplets(X_eval, Y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119938/119938 [==============================] - 145s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8782454858518958"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_eval, P_eval, N_eval = triplets_list_eval\n",
    "zeros_vect_eval = np.zeros(A_eval[:,1,1].shape) \n",
    "\n",
    "classification_model.evaluate([A_eval, P_eval, N_eval], zeros_vect_eval, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
